{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "“Exercise 7 - Question.ipynb”的副本",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luoChengwen/Tensorflow_test/blob/master/%E2%80%9CExercise_7_horse_VS_human.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbFmQdsZs5eW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import all the necessary files!\n",
        "# trained with google colab GPU\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1xJZ5glPPCRz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c44ffedd-43bc-48bf-aae1-31952a849324"
      },
      "source": [
        "# Download the inception v3 weights\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "\n",
        "# Import the inception model  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# Create an instance of the inception model from the local pre-trained weights\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n",
        "                                include_top = False, \n",
        "                                weights = None)\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "# Make all the layers in the pre-trained model non-trainable\n",
        "for layer in pre_trained_model.layers:\n",
        "  # Your Code Here\n",
        "  layer.trainable = False\n",
        "  \n",
        "# Print the model summary\n",
        "pre_trained_model.summary()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Expected Output is extremely large, but should end with:\n",
        "\n",
        "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
        "#                                                                 activation_276[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
        "#                                                                 activation_280[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
        "#                                                                 mixed9_1[0][0]                   \n",
        "#                                                                 concatenate_5[0][0]              \n",
        "#                                                                 activation_281[0][0]             \n",
        "#==================================================================================================\n",
        "#Total params: 21,802,784\n",
        "#Trainable params: 0\n",
        "#Non-trainable params: 21,802,784"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-08-09 06:05:21--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.188.128, 2404:6800:4008:c06::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.188.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M  81.5MB/s    in 1.0s    \n",
            "\n",
            "2019-08-09 06:05:23 (81.5 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n",
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_8 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_658 (Conv2D)             (None, 74, 74, 32)   864         input_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_658 (BatchN (None, 74, 74, 32)   96          conv2d_658[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_658 (Activation)     (None, 74, 74, 32)   0           batch_normalization_658[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_659 (Conv2D)             (None, 72, 72, 32)   9216        activation_658[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_659 (BatchN (None, 72, 72, 32)   96          conv2d_659[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_659 (Activation)     (None, 72, 72, 32)   0           batch_normalization_659[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_660 (Conv2D)             (None, 72, 72, 64)   18432       activation_659[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_660 (BatchN (None, 72, 72, 64)   192         conv2d_660[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_660 (Activation)     (None, 72, 72, 64)   0           batch_normalization_660[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_28 (MaxPooling2D) (None, 35, 35, 64)   0           activation_660[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_661 (Conv2D)             (None, 35, 35, 80)   5120        max_pooling2d_28[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_661 (BatchN (None, 35, 35, 80)   240         conv2d_661[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_661 (Activation)     (None, 35, 35, 80)   0           batch_normalization_661[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_662 (Conv2D)             (None, 33, 33, 192)  138240      activation_661[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_662 (BatchN (None, 33, 33, 192)  576         conv2d_662[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_662 (Activation)     (None, 33, 33, 192)  0           batch_normalization_662[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_29 (MaxPooling2D) (None, 16, 16, 192)  0           activation_662[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_666 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_29[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_666 (BatchN (None, 16, 16, 64)   192         conv2d_666[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_666 (Activation)     (None, 16, 16, 64)   0           batch_normalization_666[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_664 (Conv2D)             (None, 16, 16, 48)   9216        max_pooling2d_29[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_667 (Conv2D)             (None, 16, 16, 96)   55296       activation_666[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_664 (BatchN (None, 16, 16, 48)   144         conv2d_664[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_667 (BatchN (None, 16, 16, 96)   288         conv2d_667[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_664 (Activation)     (None, 16, 16, 48)   0           batch_normalization_664[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_667 (Activation)     (None, 16, 16, 96)   0           batch_normalization_667[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_63 (AveragePo (None, 16, 16, 192)  0           max_pooling2d_29[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_663 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_29[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_665 (Conv2D)             (None, 16, 16, 64)   76800       activation_664[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_668 (Conv2D)             (None, 16, 16, 96)   82944       activation_667[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_669 (Conv2D)             (None, 16, 16, 32)   6144        average_pooling2d_63[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_663 (BatchN (None, 16, 16, 64)   192         conv2d_663[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_665 (BatchN (None, 16, 16, 64)   192         conv2d_665[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_668 (BatchN (None, 16, 16, 96)   288         conv2d_668[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_669 (BatchN (None, 16, 16, 32)   96          conv2d_669[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_663 (Activation)     (None, 16, 16, 64)   0           batch_normalization_663[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_665 (Activation)     (None, 16, 16, 64)   0           batch_normalization_665[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_668 (Activation)     (None, 16, 16, 96)   0           batch_normalization_668[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_669 (Activation)     (None, 16, 16, 32)   0           batch_normalization_669[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_663[0][0]             \n",
            "                                                                 activation_665[0][0]             \n",
            "                                                                 activation_668[0][0]             \n",
            "                                                                 activation_669[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_673 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_673 (BatchN (None, 16, 16, 64)   192         conv2d_673[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_673 (Activation)     (None, 16, 16, 64)   0           batch_normalization_673[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_671 (Conv2D)             (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_674 (Conv2D)             (None, 16, 16, 96)   55296       activation_673[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_671 (BatchN (None, 16, 16, 48)   144         conv2d_671[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_674 (BatchN (None, 16, 16, 96)   288         conv2d_674[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_671 (Activation)     (None, 16, 16, 48)   0           batch_normalization_671[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_674 (Activation)     (None, 16, 16, 96)   0           batch_normalization_674[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_64 (AveragePo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_670 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_672 (Conv2D)             (None, 16, 16, 64)   76800       activation_671[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_675 (Conv2D)             (None, 16, 16, 96)   82944       activation_674[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_676 (Conv2D)             (None, 16, 16, 64)   16384       average_pooling2d_64[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_670 (BatchN (None, 16, 16, 64)   192         conv2d_670[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_672 (BatchN (None, 16, 16, 64)   192         conv2d_672[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_675 (BatchN (None, 16, 16, 96)   288         conv2d_675[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_676 (BatchN (None, 16, 16, 64)   192         conv2d_676[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_670 (Activation)     (None, 16, 16, 64)   0           batch_normalization_670[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_672 (Activation)     (None, 16, 16, 64)   0           batch_normalization_672[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_675 (Activation)     (None, 16, 16, 96)   0           batch_normalization_675[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_676 (Activation)     (None, 16, 16, 64)   0           batch_normalization_676[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_670[0][0]             \n",
            "                                                                 activation_672[0][0]             \n",
            "                                                                 activation_675[0][0]             \n",
            "                                                                 activation_676[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_680 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_680 (BatchN (None, 16, 16, 64)   192         conv2d_680[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_680 (Activation)     (None, 16, 16, 64)   0           batch_normalization_680[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_678 (Conv2D)             (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_681 (Conv2D)             (None, 16, 16, 96)   55296       activation_680[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_678 (BatchN (None, 16, 16, 48)   144         conv2d_678[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_681 (BatchN (None, 16, 16, 96)   288         conv2d_681[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_678 (Activation)     (None, 16, 16, 48)   0           batch_normalization_678[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_681 (Activation)     (None, 16, 16, 96)   0           batch_normalization_681[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_65 (AveragePo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_677 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_679 (Conv2D)             (None, 16, 16, 64)   76800       activation_678[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_682 (Conv2D)             (None, 16, 16, 96)   82944       activation_681[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_683 (Conv2D)             (None, 16, 16, 64)   18432       average_pooling2d_65[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_677 (BatchN (None, 16, 16, 64)   192         conv2d_677[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_679 (BatchN (None, 16, 16, 64)   192         conv2d_679[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_682 (BatchN (None, 16, 16, 96)   288         conv2d_682[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_683 (BatchN (None, 16, 16, 64)   192         conv2d_683[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_677 (Activation)     (None, 16, 16, 64)   0           batch_normalization_677[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_679 (Activation)     (None, 16, 16, 64)   0           batch_normalization_679[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_682 (Activation)     (None, 16, 16, 96)   0           batch_normalization_682[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_683 (Activation)     (None, 16, 16, 64)   0           batch_normalization_683[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_677[0][0]             \n",
            "                                                                 activation_679[0][0]             \n",
            "                                                                 activation_682[0][0]             \n",
            "                                                                 activation_683[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_685 (Conv2D)             (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_685 (BatchN (None, 16, 16, 64)   192         conv2d_685[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_685 (Activation)     (None, 16, 16, 64)   0           batch_normalization_685[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_686 (Conv2D)             (None, 16, 16, 96)   55296       activation_685[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_686 (BatchN (None, 16, 16, 96)   288         conv2d_686[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_686 (Activation)     (None, 16, 16, 96)   0           batch_normalization_686[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_684 (Conv2D)             (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_687 (Conv2D)             (None, 7, 7, 96)     82944       activation_686[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_684 (BatchN (None, 7, 7, 384)    1152        conv2d_684[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_687 (BatchN (None, 7, 7, 96)     288         conv2d_687[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_684 (Activation)     (None, 7, 7, 384)    0           batch_normalization_684[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_687 (Activation)     (None, 7, 7, 96)     0           batch_normalization_687[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_30 (MaxPooling2D) (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_684[0][0]             \n",
            "                                                                 activation_687[0][0]             \n",
            "                                                                 max_pooling2d_30[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_692 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_692 (BatchN (None, 7, 7, 128)    384         conv2d_692[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_692 (Activation)     (None, 7, 7, 128)    0           batch_normalization_692[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_693 (Conv2D)             (None, 7, 7, 128)    114688      activation_692[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_693 (BatchN (None, 7, 7, 128)    384         conv2d_693[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_693 (Activation)     (None, 7, 7, 128)    0           batch_normalization_693[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_689 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_694 (Conv2D)             (None, 7, 7, 128)    114688      activation_693[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_689 (BatchN (None, 7, 7, 128)    384         conv2d_689[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_694 (BatchN (None, 7, 7, 128)    384         conv2d_694[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_689 (Activation)     (None, 7, 7, 128)    0           batch_normalization_689[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_694 (Activation)     (None, 7, 7, 128)    0           batch_normalization_694[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_690 (Conv2D)             (None, 7, 7, 128)    114688      activation_689[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_695 (Conv2D)             (None, 7, 7, 128)    114688      activation_694[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_690 (BatchN (None, 7, 7, 128)    384         conv2d_690[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_695 (BatchN (None, 7, 7, 128)    384         conv2d_695[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_690 (Activation)     (None, 7, 7, 128)    0           batch_normalization_690[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_695 (Activation)     (None, 7, 7, 128)    0           batch_normalization_695[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_66 (AveragePo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_688 (Conv2D)             (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_691 (Conv2D)             (None, 7, 7, 192)    172032      activation_690[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_696 (Conv2D)             (None, 7, 7, 192)    172032      activation_695[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_697 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_66[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_688 (BatchN (None, 7, 7, 192)    576         conv2d_688[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_691 (BatchN (None, 7, 7, 192)    576         conv2d_691[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_696 (BatchN (None, 7, 7, 192)    576         conv2d_696[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_697 (BatchN (None, 7, 7, 192)    576         conv2d_697[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_688 (Activation)     (None, 7, 7, 192)    0           batch_normalization_688[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_691 (Activation)     (None, 7, 7, 192)    0           batch_normalization_691[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_696 (Activation)     (None, 7, 7, 192)    0           batch_normalization_696[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_697 (Activation)     (None, 7, 7, 192)    0           batch_normalization_697[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_688[0][0]             \n",
            "                                                                 activation_691[0][0]             \n",
            "                                                                 activation_696[0][0]             \n",
            "                                                                 activation_697[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_702 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_702 (BatchN (None, 7, 7, 160)    480         conv2d_702[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_702 (Activation)     (None, 7, 7, 160)    0           batch_normalization_702[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_703 (Conv2D)             (None, 7, 7, 160)    179200      activation_702[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_703 (BatchN (None, 7, 7, 160)    480         conv2d_703[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_703 (Activation)     (None, 7, 7, 160)    0           batch_normalization_703[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_699 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_704 (Conv2D)             (None, 7, 7, 160)    179200      activation_703[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_699 (BatchN (None, 7, 7, 160)    480         conv2d_699[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_704 (BatchN (None, 7, 7, 160)    480         conv2d_704[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_699 (Activation)     (None, 7, 7, 160)    0           batch_normalization_699[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_704 (Activation)     (None, 7, 7, 160)    0           batch_normalization_704[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_700 (Conv2D)             (None, 7, 7, 160)    179200      activation_699[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_705 (Conv2D)             (None, 7, 7, 160)    179200      activation_704[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_700 (BatchN (None, 7, 7, 160)    480         conv2d_700[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_705 (BatchN (None, 7, 7, 160)    480         conv2d_705[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_700 (Activation)     (None, 7, 7, 160)    0           batch_normalization_700[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_705 (Activation)     (None, 7, 7, 160)    0           batch_normalization_705[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_67 (AveragePo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_698 (Conv2D)             (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_701 (Conv2D)             (None, 7, 7, 192)    215040      activation_700[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_706 (Conv2D)             (None, 7, 7, 192)    215040      activation_705[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_707 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_67[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_698 (BatchN (None, 7, 7, 192)    576         conv2d_698[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_701 (BatchN (None, 7, 7, 192)    576         conv2d_701[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_706 (BatchN (None, 7, 7, 192)    576         conv2d_706[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_707 (BatchN (None, 7, 7, 192)    576         conv2d_707[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_698 (Activation)     (None, 7, 7, 192)    0           batch_normalization_698[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_701 (Activation)     (None, 7, 7, 192)    0           batch_normalization_701[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_706 (Activation)     (None, 7, 7, 192)    0           batch_normalization_706[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_707 (Activation)     (None, 7, 7, 192)    0           batch_normalization_707[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_698[0][0]             \n",
            "                                                                 activation_701[0][0]             \n",
            "                                                                 activation_706[0][0]             \n",
            "                                                                 activation_707[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_712 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_712 (BatchN (None, 7, 7, 160)    480         conv2d_712[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_712 (Activation)     (None, 7, 7, 160)    0           batch_normalization_712[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_713 (Conv2D)             (None, 7, 7, 160)    179200      activation_712[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_713 (BatchN (None, 7, 7, 160)    480         conv2d_713[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_713 (Activation)     (None, 7, 7, 160)    0           batch_normalization_713[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_709 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_714 (Conv2D)             (None, 7, 7, 160)    179200      activation_713[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_709 (BatchN (None, 7, 7, 160)    480         conv2d_709[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_714 (BatchN (None, 7, 7, 160)    480         conv2d_714[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_709 (Activation)     (None, 7, 7, 160)    0           batch_normalization_709[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_714 (Activation)     (None, 7, 7, 160)    0           batch_normalization_714[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_710 (Conv2D)             (None, 7, 7, 160)    179200      activation_709[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_715 (Conv2D)             (None, 7, 7, 160)    179200      activation_714[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_710 (BatchN (None, 7, 7, 160)    480         conv2d_710[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_715 (BatchN (None, 7, 7, 160)    480         conv2d_715[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_710 (Activation)     (None, 7, 7, 160)    0           batch_normalization_710[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_715 (Activation)     (None, 7, 7, 160)    0           batch_normalization_715[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_68 (AveragePo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_708 (Conv2D)             (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_711 (Conv2D)             (None, 7, 7, 192)    215040      activation_710[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_716 (Conv2D)             (None, 7, 7, 192)    215040      activation_715[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_717 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_68[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_708 (BatchN (None, 7, 7, 192)    576         conv2d_708[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_711 (BatchN (None, 7, 7, 192)    576         conv2d_711[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_716 (BatchN (None, 7, 7, 192)    576         conv2d_716[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_717 (BatchN (None, 7, 7, 192)    576         conv2d_717[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_708 (Activation)     (None, 7, 7, 192)    0           batch_normalization_708[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_711 (Activation)     (None, 7, 7, 192)    0           batch_normalization_711[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_716 (Activation)     (None, 7, 7, 192)    0           batch_normalization_716[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_717 (Activation)     (None, 7, 7, 192)    0           batch_normalization_717[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_708[0][0]             \n",
            "                                                                 activation_711[0][0]             \n",
            "                                                                 activation_716[0][0]             \n",
            "                                                                 activation_717[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_722 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_722 (BatchN (None, 7, 7, 192)    576         conv2d_722[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_722 (Activation)     (None, 7, 7, 192)    0           batch_normalization_722[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_723 (Conv2D)             (None, 7, 7, 192)    258048      activation_722[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_723 (BatchN (None, 7, 7, 192)    576         conv2d_723[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_723 (Activation)     (None, 7, 7, 192)    0           batch_normalization_723[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_719 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_724 (Conv2D)             (None, 7, 7, 192)    258048      activation_723[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_719 (BatchN (None, 7, 7, 192)    576         conv2d_719[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_724 (BatchN (None, 7, 7, 192)    576         conv2d_724[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_719 (Activation)     (None, 7, 7, 192)    0           batch_normalization_719[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_724 (Activation)     (None, 7, 7, 192)    0           batch_normalization_724[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_720 (Conv2D)             (None, 7, 7, 192)    258048      activation_719[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_725 (Conv2D)             (None, 7, 7, 192)    258048      activation_724[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_720 (BatchN (None, 7, 7, 192)    576         conv2d_720[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_725 (BatchN (None, 7, 7, 192)    576         conv2d_725[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_720 (Activation)     (None, 7, 7, 192)    0           batch_normalization_720[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_725 (Activation)     (None, 7, 7, 192)    0           batch_normalization_725[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_69 (AveragePo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_718 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_721 (Conv2D)             (None, 7, 7, 192)    258048      activation_720[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_726 (Conv2D)             (None, 7, 7, 192)    258048      activation_725[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_727 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_69[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_718 (BatchN (None, 7, 7, 192)    576         conv2d_718[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_721 (BatchN (None, 7, 7, 192)    576         conv2d_721[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_726 (BatchN (None, 7, 7, 192)    576         conv2d_726[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_727 (BatchN (None, 7, 7, 192)    576         conv2d_727[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_718 (Activation)     (None, 7, 7, 192)    0           batch_normalization_718[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_721 (Activation)     (None, 7, 7, 192)    0           batch_normalization_721[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_726 (Activation)     (None, 7, 7, 192)    0           batch_normalization_726[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_727 (Activation)     (None, 7, 7, 192)    0           batch_normalization_727[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_718[0][0]             \n",
            "                                                                 activation_721[0][0]             \n",
            "                                                                 activation_726[0][0]             \n",
            "                                                                 activation_727[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_730 (Conv2D)             (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_730 (BatchN (None, 7, 7, 192)    576         conv2d_730[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_730 (Activation)     (None, 7, 7, 192)    0           batch_normalization_730[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_731 (Conv2D)             (None, 7, 7, 192)    258048      activation_730[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_731 (BatchN (None, 7, 7, 192)    576         conv2d_731[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_731 (Activation)     (None, 7, 7, 192)    0           batch_normalization_731[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_728 (Conv2D)             (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_732 (Conv2D)             (None, 7, 7, 192)    258048      activation_731[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_728 (BatchN (None, 7, 7, 192)    576         conv2d_728[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_732 (BatchN (None, 7, 7, 192)    576         conv2d_732[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_728 (Activation)     (None, 7, 7, 192)    0           batch_normalization_728[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_732 (Activation)     (None, 7, 7, 192)    0           batch_normalization_732[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_729 (Conv2D)             (None, 3, 3, 320)    552960      activation_728[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_733 (Conv2D)             (None, 3, 3, 192)    331776      activation_732[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_729 (BatchN (None, 3, 3, 320)    960         conv2d_729[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_733 (BatchN (None, 3, 3, 192)    576         conv2d_733[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_729 (Activation)     (None, 3, 3, 320)    0           batch_normalization_729[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_733 (Activation)     (None, 3, 3, 192)    0           batch_normalization_733[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_31 (MaxPooling2D) (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_729[0][0]             \n",
            "                                                                 activation_733[0][0]             \n",
            "                                                                 max_pooling2d_31[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_738 (Conv2D)             (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_738 (BatchN (None, 3, 3, 448)    1344        conv2d_738[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_738 (Activation)     (None, 3, 3, 448)    0           batch_normalization_738[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_735 (Conv2D)             (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_739 (Conv2D)             (None, 3, 3, 384)    1548288     activation_738[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_735 (BatchN (None, 3, 3, 384)    1152        conv2d_735[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_739 (BatchN (None, 3, 3, 384)    1152        conv2d_739[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_735 (Activation)     (None, 3, 3, 384)    0           batch_normalization_735[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_739 (Activation)     (None, 3, 3, 384)    0           batch_normalization_739[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_736 (Conv2D)             (None, 3, 3, 384)    442368      activation_735[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_737 (Conv2D)             (None, 3, 3, 384)    442368      activation_735[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_740 (Conv2D)             (None, 3, 3, 384)    442368      activation_739[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_741 (Conv2D)             (None, 3, 3, 384)    442368      activation_739[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_70 (AveragePo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_734 (Conv2D)             (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_736 (BatchN (None, 3, 3, 384)    1152        conv2d_736[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_737 (BatchN (None, 3, 3, 384)    1152        conv2d_737[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_740 (BatchN (None, 3, 3, 384)    1152        conv2d_740[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_741 (BatchN (None, 3, 3, 384)    1152        conv2d_741[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_742 (Conv2D)             (None, 3, 3, 192)    245760      average_pooling2d_70[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_734 (BatchN (None, 3, 3, 320)    960         conv2d_734[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_736 (Activation)     (None, 3, 3, 384)    0           batch_normalization_736[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_737 (Activation)     (None, 3, 3, 384)    0           batch_normalization_737[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_740 (Activation)     (None, 3, 3, 384)    0           batch_normalization_740[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_741 (Activation)     (None, 3, 3, 384)    0           batch_normalization_741[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_742 (BatchN (None, 3, 3, 192)    576         conv2d_742[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_734 (Activation)     (None, 3, 3, 320)    0           batch_normalization_734[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_736[0][0]             \n",
            "                                                                 activation_737[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_14 (Concatenate)    (None, 3, 3, 768)    0           activation_740[0][0]             \n",
            "                                                                 activation_741[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_742 (Activation)     (None, 3, 3, 192)    0           batch_normalization_742[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_734[0][0]             \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate_14[0][0]             \n",
            "                                                                 activation_742[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_747 (Conv2D)             (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_747 (BatchN (None, 3, 3, 448)    1344        conv2d_747[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_747 (Activation)     (None, 3, 3, 448)    0           batch_normalization_747[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_744 (Conv2D)             (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_748 (Conv2D)             (None, 3, 3, 384)    1548288     activation_747[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_744 (BatchN (None, 3, 3, 384)    1152        conv2d_744[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_748 (BatchN (None, 3, 3, 384)    1152        conv2d_748[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_744 (Activation)     (None, 3, 3, 384)    0           batch_normalization_744[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_748 (Activation)     (None, 3, 3, 384)    0           batch_normalization_748[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_745 (Conv2D)             (None, 3, 3, 384)    442368      activation_744[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_746 (Conv2D)             (None, 3, 3, 384)    442368      activation_744[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_749 (Conv2D)             (None, 3, 3, 384)    442368      activation_748[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_750 (Conv2D)             (None, 3, 3, 384)    442368      activation_748[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_71 (AveragePo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_743 (Conv2D)             (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_745 (BatchN (None, 3, 3, 384)    1152        conv2d_745[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_746 (BatchN (None, 3, 3, 384)    1152        conv2d_746[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_749 (BatchN (None, 3, 3, 384)    1152        conv2d_749[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_750 (BatchN (None, 3, 3, 384)    1152        conv2d_750[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_751 (Conv2D)             (None, 3, 3, 192)    393216      average_pooling2d_71[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_743 (BatchN (None, 3, 3, 320)    960         conv2d_743[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_745 (Activation)     (None, 3, 3, 384)    0           batch_normalization_745[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_746 (Activation)     (None, 3, 3, 384)    0           batch_normalization_746[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_749 (Activation)     (None, 3, 3, 384)    0           batch_normalization_749[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_750 (Activation)     (None, 3, 3, 384)    0           batch_normalization_750[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_751 (BatchN (None, 3, 3, 192)    576         conv2d_751[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_743 (Activation)     (None, 3, 3, 320)    0           batch_normalization_743[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_745[0][0]             \n",
            "                                                                 activation_746[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_15 (Concatenate)    (None, 3, 3, 768)    0           activation_749[0][0]             \n",
            "                                                                 activation_750[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_751 (Activation)     (None, 3, 3, 192)    0           batch_normalization_751[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_743[0][0]             \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_15[0][0]             \n",
            "                                                                 activation_751[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFsUlwdfs_wg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ed891ddb-5e1a-49c7-aaf1-5c544a7857bc"
      },
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "\n",
        "# Expected Output:\n",
        "# ('last layer output shape: ', (None, 7, 7, 768))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "last layer output shape:  (None, 7, 7, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bsWZWp5oMq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a Callback class that stops training once accuracy reaches 99.9%\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.999):\n",
        "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BMXb913pbvFg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cd85016c-e774-4d19-b430-86ec54be9af7"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "import tensorflow as tf\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024,activation=tf.nn.relu)(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense  (1, activation =tf.nn.sigmoid)(x)           \n",
        "\n",
        "model = Model(pre_trained_model.input,x) \n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['acc'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Expected output will be large. Last few lines should be:\n",
        "\n",
        "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
        "#                                                                  activation_251[0][0]             \n",
        "#                                                                  activation_256[0][0]             \n",
        "#                                                                  activation_257[0][0]             \n",
        "# __________________________________________________________________________________________________\n",
        "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
        "# __________________________________________________________________________________________________\n",
        "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
        "# ==================================================================================================\n",
        "# Total params: 47,512,481\n",
        "# Trainable params: 38,537,217\n",
        "# Non-trainable params: 8,975,264\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_8 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_658 (Conv2D)             (None, 74, 74, 32)   864         input_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_658 (BatchN (None, 74, 74, 32)   96          conv2d_658[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_658 (Activation)     (None, 74, 74, 32)   0           batch_normalization_658[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_659 (Conv2D)             (None, 72, 72, 32)   9216        activation_658[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_659 (BatchN (None, 72, 72, 32)   96          conv2d_659[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_659 (Activation)     (None, 72, 72, 32)   0           batch_normalization_659[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_660 (Conv2D)             (None, 72, 72, 64)   18432       activation_659[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_660 (BatchN (None, 72, 72, 64)   192         conv2d_660[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_660 (Activation)     (None, 72, 72, 64)   0           batch_normalization_660[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_28 (MaxPooling2D) (None, 35, 35, 64)   0           activation_660[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_661 (Conv2D)             (None, 35, 35, 80)   5120        max_pooling2d_28[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_661 (BatchN (None, 35, 35, 80)   240         conv2d_661[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_661 (Activation)     (None, 35, 35, 80)   0           batch_normalization_661[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_662 (Conv2D)             (None, 33, 33, 192)  138240      activation_661[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_662 (BatchN (None, 33, 33, 192)  576         conv2d_662[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_662 (Activation)     (None, 33, 33, 192)  0           batch_normalization_662[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_29 (MaxPooling2D) (None, 16, 16, 192)  0           activation_662[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_666 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_29[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_666 (BatchN (None, 16, 16, 64)   192         conv2d_666[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_666 (Activation)     (None, 16, 16, 64)   0           batch_normalization_666[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_664 (Conv2D)             (None, 16, 16, 48)   9216        max_pooling2d_29[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_667 (Conv2D)             (None, 16, 16, 96)   55296       activation_666[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_664 (BatchN (None, 16, 16, 48)   144         conv2d_664[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_667 (BatchN (None, 16, 16, 96)   288         conv2d_667[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_664 (Activation)     (None, 16, 16, 48)   0           batch_normalization_664[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_667 (Activation)     (None, 16, 16, 96)   0           batch_normalization_667[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_63 (AveragePo (None, 16, 16, 192)  0           max_pooling2d_29[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_663 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_29[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_665 (Conv2D)             (None, 16, 16, 64)   76800       activation_664[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_668 (Conv2D)             (None, 16, 16, 96)   82944       activation_667[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_669 (Conv2D)             (None, 16, 16, 32)   6144        average_pooling2d_63[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_663 (BatchN (None, 16, 16, 64)   192         conv2d_663[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_665 (BatchN (None, 16, 16, 64)   192         conv2d_665[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_668 (BatchN (None, 16, 16, 96)   288         conv2d_668[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_669 (BatchN (None, 16, 16, 32)   96          conv2d_669[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_663 (Activation)     (None, 16, 16, 64)   0           batch_normalization_663[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_665 (Activation)     (None, 16, 16, 64)   0           batch_normalization_665[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_668 (Activation)     (None, 16, 16, 96)   0           batch_normalization_668[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_669 (Activation)     (None, 16, 16, 32)   0           batch_normalization_669[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_663[0][0]             \n",
            "                                                                 activation_665[0][0]             \n",
            "                                                                 activation_668[0][0]             \n",
            "                                                                 activation_669[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_673 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_673 (BatchN (None, 16, 16, 64)   192         conv2d_673[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_673 (Activation)     (None, 16, 16, 64)   0           batch_normalization_673[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_671 (Conv2D)             (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_674 (Conv2D)             (None, 16, 16, 96)   55296       activation_673[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_671 (BatchN (None, 16, 16, 48)   144         conv2d_671[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_674 (BatchN (None, 16, 16, 96)   288         conv2d_674[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_671 (Activation)     (None, 16, 16, 48)   0           batch_normalization_671[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_674 (Activation)     (None, 16, 16, 96)   0           batch_normalization_674[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_64 (AveragePo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_670 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_672 (Conv2D)             (None, 16, 16, 64)   76800       activation_671[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_675 (Conv2D)             (None, 16, 16, 96)   82944       activation_674[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_676 (Conv2D)             (None, 16, 16, 64)   16384       average_pooling2d_64[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_670 (BatchN (None, 16, 16, 64)   192         conv2d_670[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_672 (BatchN (None, 16, 16, 64)   192         conv2d_672[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_675 (BatchN (None, 16, 16, 96)   288         conv2d_675[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_676 (BatchN (None, 16, 16, 64)   192         conv2d_676[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_670 (Activation)     (None, 16, 16, 64)   0           batch_normalization_670[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_672 (Activation)     (None, 16, 16, 64)   0           batch_normalization_672[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_675 (Activation)     (None, 16, 16, 96)   0           batch_normalization_675[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_676 (Activation)     (None, 16, 16, 64)   0           batch_normalization_676[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_670[0][0]             \n",
            "                                                                 activation_672[0][0]             \n",
            "                                                                 activation_675[0][0]             \n",
            "                                                                 activation_676[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_680 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_680 (BatchN (None, 16, 16, 64)   192         conv2d_680[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_680 (Activation)     (None, 16, 16, 64)   0           batch_normalization_680[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_678 (Conv2D)             (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_681 (Conv2D)             (None, 16, 16, 96)   55296       activation_680[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_678 (BatchN (None, 16, 16, 48)   144         conv2d_678[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_681 (BatchN (None, 16, 16, 96)   288         conv2d_681[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_678 (Activation)     (None, 16, 16, 48)   0           batch_normalization_678[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_681 (Activation)     (None, 16, 16, 96)   0           batch_normalization_681[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_65 (AveragePo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_677 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_679 (Conv2D)             (None, 16, 16, 64)   76800       activation_678[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_682 (Conv2D)             (None, 16, 16, 96)   82944       activation_681[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_683 (Conv2D)             (None, 16, 16, 64)   18432       average_pooling2d_65[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_677 (BatchN (None, 16, 16, 64)   192         conv2d_677[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_679 (BatchN (None, 16, 16, 64)   192         conv2d_679[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_682 (BatchN (None, 16, 16, 96)   288         conv2d_682[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_683 (BatchN (None, 16, 16, 64)   192         conv2d_683[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_677 (Activation)     (None, 16, 16, 64)   0           batch_normalization_677[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_679 (Activation)     (None, 16, 16, 64)   0           batch_normalization_679[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_682 (Activation)     (None, 16, 16, 96)   0           batch_normalization_682[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_683 (Activation)     (None, 16, 16, 64)   0           batch_normalization_683[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_677[0][0]             \n",
            "                                                                 activation_679[0][0]             \n",
            "                                                                 activation_682[0][0]             \n",
            "                                                                 activation_683[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_685 (Conv2D)             (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_685 (BatchN (None, 16, 16, 64)   192         conv2d_685[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_685 (Activation)     (None, 16, 16, 64)   0           batch_normalization_685[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_686 (Conv2D)             (None, 16, 16, 96)   55296       activation_685[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_686 (BatchN (None, 16, 16, 96)   288         conv2d_686[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_686 (Activation)     (None, 16, 16, 96)   0           batch_normalization_686[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_684 (Conv2D)             (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_687 (Conv2D)             (None, 7, 7, 96)     82944       activation_686[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_684 (BatchN (None, 7, 7, 384)    1152        conv2d_684[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_687 (BatchN (None, 7, 7, 96)     288         conv2d_687[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_684 (Activation)     (None, 7, 7, 384)    0           batch_normalization_684[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_687 (Activation)     (None, 7, 7, 96)     0           batch_normalization_687[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_30 (MaxPooling2D) (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_684[0][0]             \n",
            "                                                                 activation_687[0][0]             \n",
            "                                                                 max_pooling2d_30[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_692 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_692 (BatchN (None, 7, 7, 128)    384         conv2d_692[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_692 (Activation)     (None, 7, 7, 128)    0           batch_normalization_692[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_693 (Conv2D)             (None, 7, 7, 128)    114688      activation_692[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_693 (BatchN (None, 7, 7, 128)    384         conv2d_693[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_693 (Activation)     (None, 7, 7, 128)    0           batch_normalization_693[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_689 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_694 (Conv2D)             (None, 7, 7, 128)    114688      activation_693[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_689 (BatchN (None, 7, 7, 128)    384         conv2d_689[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_694 (BatchN (None, 7, 7, 128)    384         conv2d_694[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_689 (Activation)     (None, 7, 7, 128)    0           batch_normalization_689[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_694 (Activation)     (None, 7, 7, 128)    0           batch_normalization_694[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_690 (Conv2D)             (None, 7, 7, 128)    114688      activation_689[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_695 (Conv2D)             (None, 7, 7, 128)    114688      activation_694[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_690 (BatchN (None, 7, 7, 128)    384         conv2d_690[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_695 (BatchN (None, 7, 7, 128)    384         conv2d_695[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_690 (Activation)     (None, 7, 7, 128)    0           batch_normalization_690[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_695 (Activation)     (None, 7, 7, 128)    0           batch_normalization_695[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_66 (AveragePo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_688 (Conv2D)             (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_691 (Conv2D)             (None, 7, 7, 192)    172032      activation_690[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_696 (Conv2D)             (None, 7, 7, 192)    172032      activation_695[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_697 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_66[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_688 (BatchN (None, 7, 7, 192)    576         conv2d_688[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_691 (BatchN (None, 7, 7, 192)    576         conv2d_691[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_696 (BatchN (None, 7, 7, 192)    576         conv2d_696[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_697 (BatchN (None, 7, 7, 192)    576         conv2d_697[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_688 (Activation)     (None, 7, 7, 192)    0           batch_normalization_688[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_691 (Activation)     (None, 7, 7, 192)    0           batch_normalization_691[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_696 (Activation)     (None, 7, 7, 192)    0           batch_normalization_696[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_697 (Activation)     (None, 7, 7, 192)    0           batch_normalization_697[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_688[0][0]             \n",
            "                                                                 activation_691[0][0]             \n",
            "                                                                 activation_696[0][0]             \n",
            "                                                                 activation_697[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_702 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_702 (BatchN (None, 7, 7, 160)    480         conv2d_702[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_702 (Activation)     (None, 7, 7, 160)    0           batch_normalization_702[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_703 (Conv2D)             (None, 7, 7, 160)    179200      activation_702[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_703 (BatchN (None, 7, 7, 160)    480         conv2d_703[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_703 (Activation)     (None, 7, 7, 160)    0           batch_normalization_703[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_699 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_704 (Conv2D)             (None, 7, 7, 160)    179200      activation_703[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_699 (BatchN (None, 7, 7, 160)    480         conv2d_699[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_704 (BatchN (None, 7, 7, 160)    480         conv2d_704[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_699 (Activation)     (None, 7, 7, 160)    0           batch_normalization_699[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_704 (Activation)     (None, 7, 7, 160)    0           batch_normalization_704[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_700 (Conv2D)             (None, 7, 7, 160)    179200      activation_699[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_705 (Conv2D)             (None, 7, 7, 160)    179200      activation_704[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_700 (BatchN (None, 7, 7, 160)    480         conv2d_700[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_705 (BatchN (None, 7, 7, 160)    480         conv2d_705[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_700 (Activation)     (None, 7, 7, 160)    0           batch_normalization_700[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_705 (Activation)     (None, 7, 7, 160)    0           batch_normalization_705[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_67 (AveragePo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_698 (Conv2D)             (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_701 (Conv2D)             (None, 7, 7, 192)    215040      activation_700[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_706 (Conv2D)             (None, 7, 7, 192)    215040      activation_705[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_707 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_67[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_698 (BatchN (None, 7, 7, 192)    576         conv2d_698[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_701 (BatchN (None, 7, 7, 192)    576         conv2d_701[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_706 (BatchN (None, 7, 7, 192)    576         conv2d_706[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_707 (BatchN (None, 7, 7, 192)    576         conv2d_707[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_698 (Activation)     (None, 7, 7, 192)    0           batch_normalization_698[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_701 (Activation)     (None, 7, 7, 192)    0           batch_normalization_701[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_706 (Activation)     (None, 7, 7, 192)    0           batch_normalization_706[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_707 (Activation)     (None, 7, 7, 192)    0           batch_normalization_707[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_698[0][0]             \n",
            "                                                                 activation_701[0][0]             \n",
            "                                                                 activation_706[0][0]             \n",
            "                                                                 activation_707[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_712 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_712 (BatchN (None, 7, 7, 160)    480         conv2d_712[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_712 (Activation)     (None, 7, 7, 160)    0           batch_normalization_712[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_713 (Conv2D)             (None, 7, 7, 160)    179200      activation_712[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_713 (BatchN (None, 7, 7, 160)    480         conv2d_713[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_713 (Activation)     (None, 7, 7, 160)    0           batch_normalization_713[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_709 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_714 (Conv2D)             (None, 7, 7, 160)    179200      activation_713[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_709 (BatchN (None, 7, 7, 160)    480         conv2d_709[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_714 (BatchN (None, 7, 7, 160)    480         conv2d_714[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_709 (Activation)     (None, 7, 7, 160)    0           batch_normalization_709[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_714 (Activation)     (None, 7, 7, 160)    0           batch_normalization_714[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_710 (Conv2D)             (None, 7, 7, 160)    179200      activation_709[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_715 (Conv2D)             (None, 7, 7, 160)    179200      activation_714[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_710 (BatchN (None, 7, 7, 160)    480         conv2d_710[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_715 (BatchN (None, 7, 7, 160)    480         conv2d_715[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_710 (Activation)     (None, 7, 7, 160)    0           batch_normalization_710[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_715 (Activation)     (None, 7, 7, 160)    0           batch_normalization_715[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_68 (AveragePo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_708 (Conv2D)             (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_711 (Conv2D)             (None, 7, 7, 192)    215040      activation_710[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_716 (Conv2D)             (None, 7, 7, 192)    215040      activation_715[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_717 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_68[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_708 (BatchN (None, 7, 7, 192)    576         conv2d_708[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_711 (BatchN (None, 7, 7, 192)    576         conv2d_711[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_716 (BatchN (None, 7, 7, 192)    576         conv2d_716[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_717 (BatchN (None, 7, 7, 192)    576         conv2d_717[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_708 (Activation)     (None, 7, 7, 192)    0           batch_normalization_708[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_711 (Activation)     (None, 7, 7, 192)    0           batch_normalization_711[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_716 (Activation)     (None, 7, 7, 192)    0           batch_normalization_716[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_717 (Activation)     (None, 7, 7, 192)    0           batch_normalization_717[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_708[0][0]             \n",
            "                                                                 activation_711[0][0]             \n",
            "                                                                 activation_716[0][0]             \n",
            "                                                                 activation_717[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_722 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_722 (BatchN (None, 7, 7, 192)    576         conv2d_722[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_722 (Activation)     (None, 7, 7, 192)    0           batch_normalization_722[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_723 (Conv2D)             (None, 7, 7, 192)    258048      activation_722[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_723 (BatchN (None, 7, 7, 192)    576         conv2d_723[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_723 (Activation)     (None, 7, 7, 192)    0           batch_normalization_723[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_719 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_724 (Conv2D)             (None, 7, 7, 192)    258048      activation_723[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_719 (BatchN (None, 7, 7, 192)    576         conv2d_719[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_724 (BatchN (None, 7, 7, 192)    576         conv2d_724[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_719 (Activation)     (None, 7, 7, 192)    0           batch_normalization_719[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_724 (Activation)     (None, 7, 7, 192)    0           batch_normalization_724[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_720 (Conv2D)             (None, 7, 7, 192)    258048      activation_719[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_725 (Conv2D)             (None, 7, 7, 192)    258048      activation_724[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_720 (BatchN (None, 7, 7, 192)    576         conv2d_720[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_725 (BatchN (None, 7, 7, 192)    576         conv2d_725[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_720 (Activation)     (None, 7, 7, 192)    0           batch_normalization_720[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_725 (Activation)     (None, 7, 7, 192)    0           batch_normalization_725[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_69 (AveragePo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_718 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_721 (Conv2D)             (None, 7, 7, 192)    258048      activation_720[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_726 (Conv2D)             (None, 7, 7, 192)    258048      activation_725[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_727 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_69[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_718 (BatchN (None, 7, 7, 192)    576         conv2d_718[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_721 (BatchN (None, 7, 7, 192)    576         conv2d_721[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_726 (BatchN (None, 7, 7, 192)    576         conv2d_726[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_727 (BatchN (None, 7, 7, 192)    576         conv2d_727[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_718 (Activation)     (None, 7, 7, 192)    0           batch_normalization_718[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_721 (Activation)     (None, 7, 7, 192)    0           batch_normalization_721[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_726 (Activation)     (None, 7, 7, 192)    0           batch_normalization_726[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_727 (Activation)     (None, 7, 7, 192)    0           batch_normalization_727[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_718[0][0]             \n",
            "                                                                 activation_721[0][0]             \n",
            "                                                                 activation_726[0][0]             \n",
            "                                                                 activation_727[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 1024)         38536192    flatten_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 1024)         0           dense_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 1)            1025        dropout_3[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 47,512,481\n",
            "Trainable params: 38,537,217\n",
            "Non-trainable params: 8,975,264\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJUf1mOsWQp-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrnL_IQ8knWA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "a3a6bdec-8785-46c5-ff1b-f730e43d1ceb"
      },
      "source": [
        "# Get the Horse or Human dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip -O /tmp/horse-or-human.zip\n",
        "\n",
        "# Get the Horse or Human Validation dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip -O /tmp/validation-horse-or-human.zip \n",
        "  \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '//tmp/horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/training')\n",
        "zip_ref.close()\n",
        "\n",
        "local_zip = '//tmp/validation-horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/validation')\n",
        "zip_ref.close()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-08-09 06:05:44--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.188.128, 2404:6800:4008:c06::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.188.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149574867 (143M) [application/zip]\n",
            "Saving to: ‘/tmp/horse-or-human.zip’\n",
            "\n",
            "/tmp/horse-or-human 100%[===================>] 142.65M  90.5MB/s    in 1.6s    \n",
            "\n",
            "2019-08-09 06:05:46 (90.5 MB/s) - ‘/tmp/horse-or-human.zip’ saved [149574867/149574867]\n",
            "\n",
            "--2019-08-09 06:05:48--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.125.128, 2404:6800:4008:c06::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.125.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11480187 (11M) [application/zip]\n",
            "Saving to: ‘/tmp/validation-horse-or-human.zip’\n",
            "\n",
            "/tmp/validation-hor 100%[===================>]  10.95M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2019-08-09 06:05:49 (131 MB/s) - ‘/tmp/validation-horse-or-human.zip’ saved [11480187/11480187]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9okX7_ovskI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "d013bf96-fd33-447f-c931-f76322b60a1e"
      },
      "source": [
        "train_base = '/tmp/training'\n",
        "validation_base = '/tmp/validation'\n",
        "\n",
        "train_horses_dir = os.path.join(train_base,'horses')\n",
        "train_humans_dir = os.path.join(train_base,'humans')\n",
        "validation_horses_dir =  os.path.join(validation_base,'horses')\n",
        "validation_humans_dir = os.path.join(validation_base,'humans')\n",
        "\n",
        "train_horses_fnames = os.listdir(train_horses_dir)\n",
        "train_humans_fnames = os.listdir(train_humans_dir)# Your Code Here\n",
        "validation_horses_fnames = os.listdir(validation_horses_dir) # Your Code Here\n",
        "validation_humans_fnames = os.listdir(validation_humans_dir)  # Your Code Here\n",
        "\n",
        "print('train_horses_fnames:', len(train_horses_fnames))\n",
        "print('train_humans_fnames:',len(train_humans_fnames))\n",
        "print('validation_horses_fnames:',len(validation_horses_fnames))\n",
        "print('validation_humans_fnames:',len(validation_humans_fnames))\n",
        "\n",
        "# Expected Output:\n",
        "# 500\n",
        "# 527\n",
        "# 128\n",
        "# 128"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_horses_fnames: 500\n",
            "train_humans_fnames: 527\n",
            "validation_horses_fnames: 128\n",
            "validation_humans_fnames: 128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O4s8HckqGlnb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "83b33204-704f-4197-8fde-8bcd015cd753"
      },
      "source": [
        "# Define our example directories and files\n",
        "\n",
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(train_base,\n",
        "                                   rescale=1/255,\n",
        "                                   rotation_range=45,\n",
        "                                   width_shift_range=.4)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(validation_base,\n",
        "                                   rescale=1/255,\n",
        "                                   rotation_range=45,\n",
        "                                   width_shift_range=.4)\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_base,\n",
        "                                                   batch_size=100,\n",
        "                                                   target_size=(150,150),\n",
        "                                                   class_mode='binary')     \n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory(validation_base,\n",
        "                                                        batch_size=100,\n",
        "                                                        target_size=(150,150),\n",
        "                                                        class_mode='binary')\n",
        "\n",
        "# Expected Output:\n",
        "# Found 1027 images belonging to 2 classes.\n",
        "# Found 256 images belonging to 2 classes."
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Blhq2MAUeyGA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "2cffaaf0-cfb3-416d-ec3f-222f58cc347f"
      },
      "source": [
        "# Run this and see how many epochs it should take before the callback\n",
        "# fires, and stops training at 99.9% accuracy\n",
        "# (It should take less than 100 epochs)\n",
        "\n",
        "callbacks = myCallback()\n",
        "history = model.fit_generator(train_generator,\n",
        "                             validation_data = validation_generator,\n",
        "                             epochs=20,\n",
        "                             steps_per_epoch=100,\n",
        "                             validation_steps=50,\n",
        "                             callbacks=[callbacks])\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py:716: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn('This ImageDataGenerator specifies '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "100/100 [==============================] - 155s 2s/step - loss: 0.0701 - acc: 0.9757 - val_loss: 0.0657 - val_acc: 0.9851\n",
            "Epoch 2/20\n",
            "100/100 [==============================] - 139s 1s/step - loss: 0.0254 - acc: 0.9913 - val_loss: 0.5220 - val_acc: 0.9353\n",
            "Epoch 3/20\n",
            "100/100 [==============================] - 142s 1s/step - loss: 0.0163 - acc: 0.9946 - val_loss: 0.8773 - val_acc: 0.9204\n",
            "Epoch 4/20\n",
            "100/100 [==============================] - 142s 1s/step - loss: 0.0110 - acc: 0.9966 - val_loss: 0.8829 - val_acc: 0.9220\n",
            "Epoch 5/20\n",
            "100/100 [==============================] - 141s 1s/step - loss: 0.0060 - acc: 0.9984 - val_loss: 0.5176 - val_acc: 0.9500\n",
            "Epoch 6/20\n",
            "100/100 [==============================] - 142s 1s/step - loss: 0.0058 - acc: 0.9988 - val_loss: 0.7345 - val_acc: 0.9390\n",
            "Epoch 7/20\n",
            "100/100 [==============================] - 143s 1s/step - loss: 0.0057 - acc: 0.9982 - val_loss: 1.7366 - val_acc: 0.8932\n",
            "Epoch 8/20\n",
            "100/100 [==============================] - 143s 1s/step - loss: 0.0044 - acc: 0.9989 - val_loss: 1.5701 - val_acc: 0.9020\n",
            "Epoch 9/20\n",
            " 99/100 [============================>.] - ETA: 1s - loss: 0.0046 - acc: 0.9991\n",
            "Reached 99.9% accuracy so cancelling training!\n",
            "100/100 [==============================] - 142s 1s/step - loss: 0.0046 - acc: 0.9991 - val_loss: 1.5096 - val_acc: 0.9132\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2Fp6Se9rKuL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "d67800b0-f289-4023-e4d0-dd34016819c8"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XmczfX+wPHXG2PflyJiEDGWYYyh\ni2wRhUoUydaVml9U3OpqL9W9LdJ+Rah0i1ylaHORktzKWIaQJVRjHdvYY/j8/vh8zzgzZjkzc2a+\nZ3k/H4/zmHPOdznvc2bm/f2czyrGGJRSSoWHIm4HoJRSqvBo0ldKqTCiSV8ppcKIJn2llAojmvSV\nUiqMaNJXSqkwokk/DIlIURE5JiK1/bmvm0TkMhHxe/9jEblKRHZ4Pd4kIh182TcPrzVVRB7K6/FK\n+aKY2wGonInIMa+HpYE/gbPO4zuMMe/n5nzGmLNAWX/vGw6MMZf74zwiMgK41RjTyevcI/xxbqWy\no0k/CBhj0pKuU5IcYYxZlNX+IlLMGJNaGLEplRP9ewwsWr0TAkTkaRH5UERmishR4FYRuUJEfhCR\nwyKyW0ReFZEIZ/9iImJEJNJ5/G9n+5ciclRE/icidXO7r7O9p4hsFpEUEXlNRL4XkWFZxO1LjHeI\nyFYROSQir3odW1REXhKRAyKyDeiRzefzsIjMyvDcGyIy0bk/QkQ2Ou/nV6cUntW5kkSkk3O/tIi8\n58S2HmiVYd9HRGSbc971ItLHeb4Z8DrQwak62+/12T7hdfydzns/ICKfiEgNXz6b3HzOnnhEZJGI\nHBSRPSLygNfrPOp8JkdEJEFELsmsKk1Elnl+z87nudR5nYPAIyLSQESWOK+x3/ncKngdX8d5j8nO\n9ldEpKQTc2Ov/WqIyAkRqZLV+1U5MMboLYhuwA7gqgzPPQ2cBnpjL+SlgNZAG+y3uXrAZmCUs38x\nwACRzuN/A/uBWCAC+BD4dx72vQg4ClznbBsLnAGGZfFefInxU6ACEAkc9Lx3YBSwHqgFVAGW2j/n\nTF+nHnAMKON17n1ArPO4t7OPAF2Ak0BzZ9tVwA6vcyUBnZz7E4BvgEpAHWBDhn1vAmo4v5NbnBgu\ndraNAL7JEOe/gSec+92dGFsAJYF/AV/78tnk8nOuAOwF7gFKAOWBOGfbg0Ai0MB5Dy2AysBlGT9r\nYJnn9+y8t1QgHiiK/XtsCHQFijt/J98DE7zez8/O51nG2b+ds20K8IzX6/wNmOv2/2Ew31wPQG+5\n/IVlnfS/zuG4+4D/OPczS+Rveu3bB/g5D/veBnzntU2A3WSR9H2Msa3X9o+B+5z7S7HVXJ5t12RM\nRBnO/QNwi3O/J7Apm30/A+5y7meX9H/3/l0A/+e9bybn/Rm41rmfU9J/F/iH17by2HacWjl9Nrn8\nnAcDK7LY71dPvBme9yXpb8shhn6e1wU6AHuAopns1w7YDojzeA3Q19//V+F00+qd0PGH9wMRaSQi\nnztf148A44Gq2Ry/x+v+CbJvvM1q30u84zD2vzQpq5P4GKNPrwX8lk28AB8AA537tziPPXH0EpEf\nnaqHw9hSdnaflUeN7GIQkWEikuhUURwGGvl4XrDvL+18xpgjwCGgptc+Pv3OcvicL8Um98xkty0n\nGf8eq4vIbBHZ6cTwToYYdhjbaSAdY8z32G8N7UWkKVAb+DyPMSm0Tj+UZOyuOBlbsrzMGFMeeAxb\n8i5Iu7ElUQBEREifpDLKT4y7scnCI6cupbOBq0SkJrb66QMnxlLAHOCf2KqXisB/fYxjT1YxiEg9\nYBK2iqOKc95fvM6bU/fSXdgqI8/5ymGrkXb6EFdG2X3OfwD1szguq23HnZhKez1XPcM+Gd/fc9he\nZ82cGIZliKGOiBTNIo4ZwK3YbyWzjTF/ZrGf8oEm/dBVDkgBjjsNYXcUwmt+BsSISG8RKYatJ65W\nQDHOBu4VkZpOo97fs9vZGLMHWwXxDrZqZ4uzqQS2njkZOCsivbB1z77G8JCIVBQ7jmGU17ay2MSX\njL3+3Y4t6XvsBWp5N6hmMBP4q4g0F5ES2IvSd8aYLL85ZSO7z3keUFtERolICREpLyJxzrapwNMi\nUl+sFiJSGXux24PtMFBUREbidYHKJobjQIqIXIqtYvL4H3AA+IfYxvFSItLOa/t72OqgW7AXAJUP\nmvRD19+AodiG1cnYBtcCZYzZC9wMTMT+E9cHVmNLeP6OcRKwGFgHrMCW1nPyAbaOPq1qxxhzGBgD\nzMU2hvbDXrx88Tj2G8cO4Eu8EpIxZi3wGvCTs8/lwI9exy4EtgB7RcS7msZz/FfYapi5zvG1gUE+\nxpVRlp+zMSYF6AbciL0QbQY6OptfAD7Bfs5HsI2qJZ1qu9uBh7CN+pdleG+ZeRyIw1585gEfecWQ\nCvQCGmNL/b9jfw+e7Tuwv+c/jTHLc/neVQaexhGl/M75ur4L6GeM+c7teFTwEpEZ2MbhJ9yOJdjp\n4CzlVyLSA9tT5iS2y98ZbGlXqTxx2keuA5q5HUso0Ood5W/tgW3YuuyrgRu04U3llYj8EztW4B/G\nmN/djicUaPWOUkqFES3pK6VUGAm4Ov2qVauayMhIt8NQSqmgsnLlyv3GmOy6SAMBmPQjIyNJSEhw\nOwyllAoqIpLTqHRAq3eUUiqsaNJXSqkwoklfKaXCSI5JX0Smi8g+Efk5i+3iLJawVUTWikiM17ah\nIrLFuQ31Z+BKKaVyz5eS/jtksyoRdm7yBs5tJHZOFJyJmR7HLt4QBzwuIpXyE6xSSqn8yTHpG2OW\nYieiysp1wAxj/QBUFLus29XAQmPMQWPMIewEU9ldPJRSShUwf9Tp1yT9gglJznNZPa+UUsolAdFP\n35mPeyRA7do5rYWhlFK5dPYsnDwJJ07Yn6dP2+fOnbM3z/38/szvOWrWhJEjC/Sj8EfS30n61YNq\nOc/tBDpleP6bzE5gjJmCnaub2NhYnQxIBZ5z5+DwYTh2DM6csUnD158Fta/3MUWLQsmS9laq1Pn7\nubnl9riICJB8LMZ27lz6RJybn7k95vRp//0tFKQrrgiKpD8PGCUis7CNtinGmN0isgC7Eo6n8bY7\ndqpdpQLDmTOQnAz79sHevfaW1f3kZEhN9e/rR0TYW/HiOf8sXhzKlk3/2Hufc+fg1Cmb4E6dOn87\ncCD9Y+/bmTP5i18k54vFuXNZJ+I/8zj5akQElC5tXzfjzypVMn8+48/ixe2FskiR7H/6so+/fubn\nApoLOSZ9EZmJLbFXFZEkbI+cCABjzJvAF8A1wFbs4szDnW0HReQp7KpGAOONMdk1CCuVfydO+JbE\n9+2zCTEzJUrAxRfbW82aEBNj7190EZQr53uizixxe+4XK1Zo/+RZOnvWJt6sLgqZ3TJeVHLat2hR\nqFTJfo6+JOOcfpYqZT87lWcBN7VybGys0bl3VBpjICXFtyS+d6+tfslM+fLnE7cnoWd1v1w59xOy\nUrkkIiuNMbE57aeXTOWOY8dgz570t927z9/3TuaZ1ceKQNWq55N1XFzWSbxaNVtCVEpp0ld+lJpq\nk3RWidz7llmJvEgRm6SrV7c/mzbNukRetap+zVcqD/S/RmXPU72SXancc0tOtvtnVKEC1Khhk3ls\nrP3puXmer17dNsIVLVr471GpMKJJP1wZYxN3UlLOyfzUqQuPL178fLKOjIS2bS9M4p4Su1atKBUw\nNOmHunPn4LffYMMG2LjR/vTcP3Lkwv2rVj2fsNu3zzyRV69ue2RoY6dSQUeTfqhITYVff02f1Dds\ngF9+sV3nPKpXh8aNYfBg+7NOnfSl8ogI996DUqrAadIPNqdOwebN55O65+fmzekH29SubZN6p04Q\nFWXvN24MlSu7FrpSyn2a9APVsWO2lJ6xSubXX22VDdjeLvXq2WTeq9f55N6oke1rrpRSGWjSd9uh\nQxeW2jdutPXwHsWKQcOGEB0NAwacT+4NG2ojqVIqVzTpFwZjbHfGjPXtGzbY3jEeJUvaUnq7djBi\nhE3uUVFQv77WtSul/EKTfkFbtgyGDIHt288/V7asTeY9etgSuye516mj/dSVUgVKk35BMQYmToS/\n/x3q1oWXXjqf3GvW1O6OSilXaNIvCIcPw/Dh8Mkn0LcvTJ9uR6UqpZTL/LFcovK2Zo2dauCzz2xJ\nf84cTfhKqYChSd+fpk2z0xGcPAnffANjxmg1jlIqoGjS94cTJ+C222yPm/btYfVq2wNHKaUCjCb9\n/Nqyxa5r+fbb8OijsGCBnf5XKaUCkDbk5sdHH9kG24gI+OIL6NnT7YiUUipbWtLPizNnYOxY6NfP\n9rNfvVoTvlIqKGhJP7eSkuDmm2H5chg9GiZMsHPLK6VUENCknxsLF8Itt9iZLmfNsslfKaWCSMhU\n75w5Y6vYk5IK4OTnzsH48XD11XbO+RUrNOErpYJSyCT9Xbugf3+YPNnPJ96/H665Bh5/3Jbyf/zR\nToqmlFJBKGSSfp06NjdPnZp+LZF8+fFHiImBJUvgzTfhvfegTBk/nVwppQpfyCR9gPh4O1PxJ5/k\n80TGwGuvQYcOdtbL5cvhjjt0dK1SKuiFVNLv0cOW+N98Mx8nOXoUBg6Eu++2dfirVkGrVn6LUSml\n3BRSSb9oUVsg//pr2LQpDydYvx5at4b//AeefRY+/RQqVfJ7nEop5ZaQSvpgp8CJiMhDaf+99yAu\nzk6LvHixnQe/SMh9PEqpMBdyWe3ii+0U9u+8Y+dBy9GpU3DnnXZ1q9hYO7q2U6cCjlIppdzhU9IX\nkR4isklEtorIuEy21xGRxSKyVkS+EZFaXtueF5H1IrJRRF4VKfjW0Ph4W2D/8MMcdty+3c6GOXmy\nLdkvXgw1ahR0eEop5Zock76IFAXeAHoCUcBAEYnKsNsEYIYxpjkwHvinc+xfgHZAc6Ap0Bro6Lfo\ns3DllXZVwkmTstlp/nzbHXPbNlt3/+yzUEwHKCulQpsvJf04YKsxZpsx5jQwC7guwz5RwNfO/SVe\n2w1QEigOlAAigL35DTonIrbGZsUKWLkyw8bUVBg3Dvr0gXr17A59+hR0SEopFRB8Sfo1gT+8Hic5\nz3lLBPo6928AyolIFWPM/7AXgd3ObYExZmPGFxCRkSKSICIJycnJuX0PmRoyBEqXztCgu2cPXHUV\nPPec7ebz/fc28SulVJjwV0PufUBHEVmNrb7ZCZwVkcuAxkAt7IWii4h0yHiwMWaKMSbWGBNbrVo1\nvwRUoYLtbv/BB5CSAnz7LbRsCT/9BDNm2KtByZJ+eS2llAoWviT9ncClXo9rOc+lMcbsMsb0Nca0\nBB52njuMLfX/YIw5Zow5BnwJXOGXyH0QH2978MwYvBC6dIHy5W3SHzy4sEJQSqmA4kvSXwE0EJG6\nIlIcGADM895BRKqKiOdcDwLTnfu/Y78BFBORCOy3gAuqdwpKq3qHaF1xM5Pm18Tc2A8SEqBp08J6\neaWUCjg5Jn1jTCowCliATdizjTHrRWS8iHhaQDsBm0RkM3Ax8Izz/BzgV2Adtt4/0Rgz379vIQsr\nV0JMDPFHn2cjUXx31ywoV65QXloppQKVGGPcjiGd2NhYk5CQkPcTGANTpti5cy6+mBMz5lDzhjh6\n9ICZM/0Xp1JKBRIRWWmMic1pv9AakXv8OAwdavtrdu4Mq1ZRulMcQ4faBVb2FnhnUaWUCmyhk/R/\n/x3atIF//9uucvXFF1C1KmCvAWfOwPTpOZxDKaVCXOgk/apV7cQ7CxbAo4+mmyytUSNb8J88Gc6e\ndTFGpZRyWegk/dKlYdEi6NYt083x8fDbb/DVV4Ucl1JKBZDQSfqQ7cpW118P1avnc4EVpZQKcqGV\n9LMREQEjRsDnn9sSv1JKhaOwSfoAt99uvwxMmeJ2JEop5Y6wSvq1a8O118LUqXD6tNvRKKVU4Qur\npA+2QXffPpg71+1IlFKq8IVd0r/6aqhbN4cFVpRSKkSFXdIvUsROpf/tt7Cx0KZ+U0qpwBB2SR9g\n+HDbm0e7byqlwk1YJv2LLoJ+/eDdd+10PUopFS7CMumDbdBNSYFZs9yORCmlCk/YJv327aFJE23Q\nVUqFl7BN+iK2tL9yJaxY4XY0SilVOMI26YNdKrdMGW3QVUqFj7BO+uXLwy232BW1Dh1yOxqllCp4\nYZ30wVbxnDwJM2a4HYlSShW8sE/6LVvaBbfefNMur6uUUqEs7JM+2NL+L7/AN9+4HYlSShUsTfrA\nTTdBpUrafVMpFfo06QOlStmpGebOhT173I5GKaUKjiZ9xx13QGoqTJvmdiRKKVVwNOk7GjaErl3t\nqlpnz7odjVJKFQxN+l7i4+H33+GLL9yORCmlCoYmfS99+kCNGtqgq5QKXZr0vURE2MXTv/oKtm93\nOxqllPI/n5K+iPQQkU0islVExmWyvY6ILBaRtSLyjYjU8tpWW0T+KyIbRWSDiET6L3z/GzHCTsY2\nZYrbkSillP/lmPRFpCjwBtATiAIGikhUht0mADOMMc2B8cA/vbbNAF4wxjQG4oB9/gi8oFx6KfTu\nbXvx/Pmn29EopZR/+VLSjwO2GmO2GWNOA7OA6zLsEwV87dxf4tnuXByKGWMWAhhjjhljTvgl8gIU\nHw/JyfDxx25HopRS/uVL0q8J/OH1OMl5zlsi0Ne5fwNQTkSqAA2BwyLysYisFpEXnG8O6YjISBFJ\nEJGE5OTk3L8LP+vWDerX1wZdpVTo8VdD7n1ARxFZDXQEdgJngWJAB2d7a6AeMCzjwcaYKcaYWGNM\nbLVq1fwUUt4VKWIHa333Hfz8s9vRKKWU//iS9HcCl3o9ruU8l8YYs8sY09cY0xJ42HnuMPZbwRqn\naigV+ASI8UvkBWz4cCheHCZPdjsSpZTyH1+S/gqggYjUFZHiwABgnvcOIlJVRDznehCY7nVsRRHx\nFN+7ABvyH3bBq1oV+ve38+wfO+Z2NEop5R85Jn2nhD4KWABsBGYbY9aLyHgR6ePs1gnYJCKbgYuB\nZ5xjz2KrdhaLyDpAgLf8/i4KSHw8HDliV9ZSSqlQICbAVg6JjY01CQkJbocB2EVVoqOhWDG7gLqI\n2xEppVTmRGSlMSY2p/10RG42RGxpf/Vq+Oknt6NRSqn806Sfg1tvhbJltfumUio0aNLPQblyNvF/\n+CEcPOh2NEoplT+a9H1w551w6hS8+67bkSilVP5o0vdBdDRccQW8+aZt3FVKqWClSd9H8fGweTN8\n/XXO+yqlVKDSpO+j/v2hShVt0FVKBTdN+j4qWdJOzfDJJ7Brl9vRKKVU3mjSz4WRI+2i6dOmuR2J\nUkrljSb9XGjQwE67PGUKpKa6HY1SSuWeJv1cio+HpCT4/HO3I1FKqdzTpJ9LvXtDzZraoKuUCk6a\n9HOpWDG4/XZYsAB+/dXtaFRhOXcO7r4bHnkEDh92Oxql8k6Tfh6MGAFFi+oCK+FkwgR47TV45hm7\nlOaLL9pR2koFG036eVCzJvTpA9Onw59/uh2NKmg//ggPP2zHaqxeDXFxcN990LAhvP227dGlVLDQ\npJ9H8fFw4ADMmeN2JKogpaTAwIH2Qj9lCrRoAV9+aUdmV68Ot91mp+mYN0+n6FDBQZN+HnXtCpdd\npg26ocwYO9ne77/b1dMqVjy/rXNn+w1gzhw4cwauuw46dIBly9yLVylfaNLPoyJFbEL4/ntYt87t\naFRBeOcdmDULxo+3E+5lJAI33gjr19v2nW3bbOLv0wd+/rnQw1XKJ5r082HYMChRQkv7oeiXX2DU\nKOjSBf7+9+z3LVbMjtbeuhX+8Q9YuhSaN7d/H7//XijhKuUzTfr5UKUK3HwzvPceHD3qdjTKX06d\nggEDoHRp+7stWtS340qXhgcftF15//Y3+y2hYUN7/8CBgo1ZKV9p0s+nO++EY8fggw/cjkT5ywMP\nQGKiXTTnkktyf3yVKvDCC7BlC9xyC7z8MtSrZ7t7Hj/u/3iVyg1N+vnUtq3tvTFpkvbeCAXz5tn+\n+GPGwDXX5O9cl15qu/WuXWsbfh95xDb+v/mmbfxVyg2a9PNJxHbfTEyEH35wOxqVH0lJdvrsli3h\nn//033mbNLFTci9bZpN+fLx9bvZsLSiowqdJ3w8GDbILqGuDbvA6exZuvdUOtps1yzbQ+1u7draR\nd/58e/6bb7YDvRYv9v9rKZUVTfp+ULYsDB5sS27aYBecnnkGvv0W/vUv2/haUESgVy9Ys8Z2Cd23\nD666Crp3h1WrCu51lfLQpO8nd95pS4nvvON2JCq3vvsOnnzSlvSHDCmc1yxaFIYOhU2b7Dw+K1dC\nq1Z29K9O5KcKkpgAq1SMjY01CQkJboeRJ+3bw9699h+5iF5Og8LBg3ZqhRIlbEm7XDl34khJsT1+\nXnoJTp+2/f4ffdRO9aCUL0RkpTEmNqf9NDX5UXy8HaCjdbTBwRj4619hzx5bj+9WwgeoUAGeftr+\n/YwYYUf4XnYZPPYYHDniXlwq9PiU9EWkh4hsEpGtIjIuk+11RGSxiKwVkW9EpFaG7eVFJElEXvdX\n4IGoXz+oWlUbdIPFpEm2V82zz9qqlUBQo4aNa+NGuPZaeOopO5XzK6/ojK7KP3JM+iJSFHgD6AlE\nAQNFJCrDbhOAGcaY5sB4IGOHt6eApfkPN7CVKGFnXZw3D3budDsalZ21a2HsWOjZE+691+1oLtSg\nAXz4IaxYYceB3HsvNGpkRwjrVM4qP3wp6ccBW40x24wxp4FZwHUZ9okCvnbuL/HeLiKtgIuB/+Y/\n3MB3xx32n/Ktt9yORGXl+HE7zUKlSrbhPZDbX2JjYdEi+O9/oXJl29DcsiV88YX28Vd548ufe03g\nD6/HSc5z3hKBvs79G4ByIlJFRIoALwL35TfQYFGvHlx9tU36qaluR6Myc++9dkK1f/8bLrrI7Wh8\n062bLfXPnAknTtiqn06ddECgyj1/lXHuAzqKyGqgI7ATOAv8H/CFMSYpu4NFZKSIJIhIQnJysp9C\nck98POzaZQfhqMDy4YcwdSqMG2fXRAgmRYrYbygbNsDrr9sL1xVXwA03wI4dbkengkWOXTZF5Arg\nCWPM1c7jBwGMMZkOVBeRssAvxphaIvI+0AE4B5QFigP/MsZc0BjsEcxdNj1SU6FuXWjc2H4tV4Fh\n+3bbPTMqyo6MjYhwO6L8OXbMdvF8/nlb768LuIQ3f3bZXAE0EJG6IlIcGADMy/BiVZ2qHIAHgekA\nxphBxpjaxphI7LeBGdkl/FDhmV994UI706Jy35kzduCTiK0iCfaED3Yk+KOP2tHE339vV/JSKic5\nJn1jTCowClgAbARmG2PWi8h4Eenj7NYJ2CQim7GNts8UULxBY8QIm/wnT3Y7EgW2v/uPP9q2lshI\nt6Pxr+HDbT//l15yOxIVDHREbgHq398uoJ2UBKVKuR1N+Fq0yM5tM2KEXdw8FD3wAEycaKdwqFPH\n7WiUG3REbgC48047zH/OHLcjCV/79tnJ8Bo1souZhKrRo+3P115zNw4V+DTpF6AuXeyMjTpC1x3n\nztlJzQ4dsr12Spd2O6KCc+ml9pvlW2/p0p0qe5r0C5CILe3/7386ba4bXn4ZvvrKVns0a+Z2NAVv\nzBg7T8/06W5HogKZ1ukXsEOHbPfNYsXs6M9evdyOKDysXGn7sPfqBR99ZC/A4aBDB9uGtHWr7wu6\nq9CgdfoBolIlO2qyVi3o3RvuuUcnzipoR4/aQUzVq9uBWOGS8MHOJ7Rjh51ITqnMaNIvBI0a2cR/\n993w6qt2MfVNm9yOKnT93//Btm3w/vt2vppw0qePnQpk4kS3I1GBSpN+ISlZ0k6PO28e/PGHncr3\nnXd00ix/mzHDzqnz+OO2qiPcFC1q5xZavlzn5VGZ06RfyHr3hsREO3vi8OF2iT5dJMM/Nm+2pfyO\nHeHhh92Oxj06WEtlR5O+C2rWtKtrjR9vV2yKibEzKKq8+/NPW49fooQt6YdzI2bZsnYakDlz4Lff\n3I5GBRpN+i4pWtTOm/Ltt3ZN1L/8BSZMsH3LVe6NGwerV8Pbb9tG83A3erRtwNbBWiojTfoua98e\n1qyx1T7332/nSd+71+2ogsvnn9s++aNH24ZMZQdr3XSTHayl1YfKmyb9AFC5su1L/q9/wZIldprc\nhQvdjio47NoFw4bZz+z5592OJrCMHauDtdSFNOkHCBG7+MqKFfYicPXVtsrizBm3IwtcZ8/ahvAT\nJ+w0CyVLuh1RYImNtT2YXnlFV3FT52nSDzDNmkFCgp0R8rnn7D/t9u1uRxWYnn3WfjN6/XW4/HK3\nowlMOlhLZaRJPwCVLm2nAJ492y6J16KFLcmq85Yvt33xBw601Tsqc71762AtlZ4m/QDWv79t5I2K\nst0RR4yA48fdjsp9hw7ZZF+7Nrz5ZnhNs5BbnsFa//ufvSmlST/ARUba9Vwfesg2yMXGwtq1bkfl\nHmPg9tttA+6sWVC+vNsRBT4drKW8adIPAhERdh3UhQvh8GGIi4M33gjPKRymTLE9nZ55xn4OKmdl\ny8Idd9jPbccOt6NRbtOkH0S6drWl/K5dYdQo6NvXrswVLn7+2VZVdO8O993ndjTBZfRoKFJEB2sp\nTfpBp1o1mD/fNsx9/rntn/7dd25HVfBOnLDtGuXLw7vv2gSmfFerlg7WUpb+6wShIkXsKkn/+5/t\nm96pEzz5pO23HqrGjoX16+G99+w8+Sr3xoyxaw1Mm+Z2JMpNmvSDWKtWdhnGQYPgiSfsmrxJSW5H\n5X8ffQSTJ9tpKrp3dzua4KWDtRRo0g965crZOeRnzLBLBEZHw6efuh2V//z2m+2q2ro1PP2029EE\nv7Fj7Wc6d67bkSi3aNIPEYMH21kmIyPh+uttw92pU25HlT+pqfZbzNmztntm8eJuRxT8eveG+vV1\nsFY406QfQho0sCNVx4yxUxO0aQMbN7odVd49+SR8/72t2qlXz+1oQoNnsNYPP+hgrXClST/ElChx\nvmfPrl22HnfatODr079kie2LP3y4HX2r/GfYMKhYUQdrhStN+iHqmmvssoxt29o68YEDISXF7ah8\ns3+/nT2zYUPtV14QdLBWeBMTYEXA2NhYk5CQ4HYYIePsWTtb52OP2blqZs601T5uOnMGDhywyT05\n2f70vr9sme2e+eOPdrI55X8LFiSqAAAZu0lEQVRJSVC3rm370fr90CAiK40xsTnup0k/PCxfDrfc\nAjt32l4w99/vnwFOxti+395JO+PPjM8dPpz1+SpUgIsusktJDh6c//hU1m69FebNgz/+sJ+7Cm5+\nTfoi0gN4BSgKTDXGPJthex1gOlANOAjcaoxJEpEWwCSgPHAWeMYYk+0kwZr0C87hw3aysjlzoFs3\n280z40CnM2cuTNQ5JfTTpzN/vYgIO4K4alXfflapYo9RhWPlStvm8+KLtiunCm5+S/oiUhTYDHQD\nkoAVwEBjzAavff4DfGaMeVdEugDDjTGDRaQhYIwxW0TkEmAl0NgYk2VZT5N+wTLGDsW/5x47pUGb\nNukTeXb1/hUrXpiss0vk5crptMeBrmNHW6//669QrJjb0aj88DXp+/JrjgO2GmO2OSeeBVwHbPDa\nJwrwlBWWAJ8AGGM2e3YwxuwSkX3YbwPZfMFXBUkERo6Edu3grrvg999tko6MzD6Rayk8NI0da8d1\nfPyxnZtHhT5fkn5N4A+vx0lAxqbARKAvtgroBqCciFQxxhzw7CAicUBx4NeMLyAiI4GRALVr185N\n/CqPmjSBb75xOwrltl694LLLbPdNTfrhwV9dNu8DOorIaqAjsBNbhw+AiNQA3sNW+5zLeLAxZoox\nJtYYE1utWjU/haSUyokO1go/viT9ncClXo9rOc+lMcbsMsb0Nca0BB52njsMICLlgc+Bh40xP/gl\naqWU3wwbBpUqadfNcOFL0l8BNBCRuiJSHBgAzPPeQUSqiojnXA9ie/Lg7D8XmGGMmeO/sJVS/lKm\njB2s9fHHsH2729GogpZj0jfGpAKjgAXARmC2MWa9iIwXkT7Obp2ATSKyGbgYeMZ5/ibgSmCYiKxx\nbjrcRqkAM2qUHbfx6qtuR6IKmg7OUkoBdrDWp5/a0bo6WCv4+NplU+feUUoBdnbWY8dg6lS3I1EF\nSZO+UgqwK7F17GireHRlrdClSV8plWbsWDtg7+OP3Y5EFRRN+kqpNJ7BWi++GHxrMCjfaNJXSqUp\nUsTW7f/0kw7WClWa9JVS6QwdqoO13HDoEPz8c8G/jiZ9pVQ6nsFac+fCtm1uRxP6/vzTXmDr17cr\n3BV0tZomfaXUBXSwVsE7d86uZNeoEfztb9C6Nbz3XsFPR65JXyl1gZo1YcAAmDYt+5XOVN4sWQJx\ncXY1uwoVYMECeyuM5UE16SulMqWDtfxv/XrbQ6pLF9i3z65et2oVdO9eeDFo0ldKZSomBjp10sFa\n/rBzJ4wYAc2bw7Jl8NxzsGmTXQfaH2tV54YmfaVUlsaOtQunf/SR25EEpyNH4JFHoEEDW6q/5x67\nNOUDD0CpUu7EpElfKZWla6+1CUsHa+XOmTPwxht2oNszz8B118Evv9heOlWquBubJn2lVJaKFLEr\na61YAcuXux1N4DPGfitq0sT2gIqKsgPdZs6EevXcjs7SpK+UypYO1vLN999Du3bQrx9ERMBnn9le\nOq1bux1Zepr0lVLZKlMG7rzTDtb69Ve3owk8mzZB377Qvj3s2AFvvQWJibZqrKD73OdFMbcD8MWZ\nM2dISkri1KlTboeiAkjJkiWpVasWERERbocS8kaNggkTbE+eV15xO5rAsHcvjB8PkyfbRtmnnrLd\nXMuUcTuy7AVF0k9KSqJcuXJERkYigXjpVIXOGMOBAwdISkqibt26bocT8i65xA7Wmj4dnnwSKlZ0\nOyL3HD9uq7qefx5OnrRTVjz+OFx0kduR+SYoqndOnTpFlSpVNOGrNCJClSpV9NtfIQr3wVqpqfa9\nN2gAjz1mB1StX2976QRLwocgSfqAJnx1Af2bKFwtW54frHXmjNvRFB5jbKNsdDTcfjtERtoBVh99\nBJdf7nZ0uRc0SV8p5b5wG6y1YgV07gy9e9sL3Ucfne+lE6w06fvgwIEDtGjRghYtWlC9enVq1qyZ\n9vj06dM+nWP48OFs2rQp233eeOMN3n//fX+ErFSBCJfBWtu22WmO4+JgwwZbhbN+ve2lE+xfMIOi\nIddtVapUYc2aNQA88cQTlC1blvvuuy/dPsYYjDEUyWIijbfffjvH17nrrrvyH2whS01NpVgx/TMK\nF56Vtf7v/2yJt317tyPyrwMH4OmnbZIvVsxOoXD//VC+vNuR+U/wlfTvvddWLPrzdu+9eQpl69at\nREVFMWjQIJo0acLu3bsZOXIksbGxNGnShPHjx6ft2759e9asWUNqaioVK1Zk3LhxREdHc8UVV7Bv\n3z4AHnnkEV5++eW0/ceNG0dcXByXX345y53hkMePH+fGG28kKiqKfv36ERsbm3ZB8vb444/TunVr\nmjZtyp133olximWbN2+mS5cuREdHExMTw44dOwD4xz/+QbNmzYiOjubhhx9OFzPAnj17uOyyywCY\nOnUq119/PZ07d+bqq6/myJEjdOnShZiYGJo3b85nn32WFsfbb79N8+bNiY6OZvjw4aSkpFCvXj1S\nnRm8Dh06lO6xCnxDhkDlyqE1WOvkSTsJWv36ts1i6FDYutV2wwylhA/BmPQDzC+//MKYMWPYsGED\nNWvW5NlnnyUhIYHExEQWLlzIhg0bLjgmJSWFjh07kpiYyBVXXMH06dMzPbcxhp9++okXXngh7QLy\n2muvUb16dTZs2MCjjz7K6tWrMz32nnvuYcWKFaxbt46UlBS++uorAAYOHMiYMWNITExk+fLlXHTR\nRcyfP58vv/ySn376icTERP72t7/l+L5Xr17Nxx9/zOLFiylVqhSffPIJq1atYtGiRYwZMwaAxMRE\nnnvuOb755hsSExN58cUXqVChAu3atUuLZ+bMmfTv31+/LQQRz2CtTz4J/sFa587ZidAuvxzGjYMO\nHWDtWjvA6pJL3I6uYATff5pTEg4U9evXJzY2Nu3xzJkzmTZtGqmpqezatYsNGzYQFRWV7phSpUrR\ns2dPAFq1asV3332X6bn79u2bto+nRL5s2TL+/ve/AxAdHU2TJk0yPXbx4sW88MILnDp1iv3799Oq\nVSvatm3L/v376d27N2AHNwEsWrSI2267jVLOtH+VK1fO8X13796dSpUqAfbiNG7cOJYtW0aRIkX4\n448/2L9/P19//TU333xz2vk8P0eMGMGrr75Kr169ePvtt3nvvfdyfD0VWO66C154IbgHay1caKtu\nEhOhVSt4913baBvqtKSfT2W8ht9t2bKFV155ha+//pq1a9fSo0ePTPuRFy9ePO1+0aJFs6zaKFGi\nRI77ZObEiROMGjWKuXPnsnbtWm677bY89WcvVqwY586dA7jgeO/3PWPGDFJSUli1ahVr1qyhatWq\n2b5ex44d2bx5M0uWLCEiIoJGjRrlOjblrksusQ2dwbiy1sqVcPXVtp99SoqdDO2nn8Ij4YMmfb86\ncuQI5cqVo3z58uzevZsFCxb4/TXatWvH7NmzAVi3bl2m1UcnT56kSJEiVK1alaNHj/KR07+uUqVK\nVKtWjfnz5wM2kZ84cYJu3boxffp0Tp48CcDBgwcBiIyMZOXKlQDMmTMny5hSUlK46KKLKFasGAsX\nLmTnzp0AdOnShQ8//DDtfJ6fALfeeiuDBg1i+PDh+fo8lHvGjLGjU996y+1IcpaaCnPm2Oqb2Fjb\nFXPiRDvd8YABhb+QiZt8eqsi0kNENonIVhEZl8n2OiKyWETWisg3IlLLa9tQEdni3Ib6M/hAExMT\nQ1RUFI0aNWLIkCG0K4DOvKNHj2bnzp1ERUXx5JNPEhUVRYUKFdLtU6VKFYYOHUpUVBQ9e/akTZs2\nadvef/99XnzxRZo3b0779u1JTk6mV69e9OjRg9jYWFq0aMFLL70EwP33388rr7xCTEwMhw4dyjKm\nwYMHs3z5cpo1a8asWbNo0KABYKufHnjgAa688kpatGjB/fffn3bMoEGDSElJ4eabb/bnx6MKUYsW\ntnQcyIO1Dh600yXUrw/9+0NSku1uun27vWg5X6bDi6erYVY3oCjwK1APKA4kAlEZ9vkPMNS53wV4\nz7lfGdjm/Kzk3K+U3eu1atXKZLRhw4YLngtXZ86cMSdPnjTGGLN582YTGRlpzpw543JUuTdz5kwz\nbNiwfJ9H/zbcNX++MWDMBx+4HUl669cbc8cdxpQubePr1MmYuXONSU11O7KCAySYHPK5Mcanhtw4\nYKsxZhuAiMwCrgO86xWigLHO/SXAJ879q4GFxpiDzrELgR7AzFxdmVSaY8eO0bVrV1JTUzHGMHny\n5KDr+RIfH8+iRYvSevCo4HXNNdCwoa0qGTDA3YFL587Bl1/abx7//a8txQ8aBHffbadQUJYv2aIm\n8IfX4ySgTYZ9EoG+wCvADUA5EamSxbE1M76AiIwERgLUrl3b19jDUsWKFdPq2YPVpEmT3A5B+Yln\nsFZ8vJ2PpkOHwo/h6FF45x147TXYssU2Mj/9NIwcCdWqFX48gc5fzRf3AR1FZDXQEdgJnPX1YGPM\nFGNMrDEmtpr+lpQKKp7BWk5TUKHZts3OBVSrli3NV64MH3xg6+sfflgTflZ8Sfo7gUu9Htdynktj\njNlljOlrjGkJPOw8d9iXY5VSwa10aVvSL4zBWsbYJQivv94uOv7aa3Y+oB9+sLeBA8GrR7TKhC9J\nfwXQQETqikhxYAAwz3sHEakqIp5zPQh4hpguALqLSCURqQR0d55TSoWQu+6yc9UU1ECtkyftmIAW\nLaBLFzvvz0MP2eUJP/gA2mSscFZZyjHpG2NSgVHYZL0RmG2MWS8i40Wkj7NbJ2CTiGwGLgaecY49\nCDyFvXCsAMZ7GnWVUqGjRg1byp4+HbLp3ZtrO3faqppLL4URI+xz06bB77/bevuaF7QQqpz4VKdv\njPnCGNPQGFPfGONJ6I8ZY+Y59+cYYxo4+4wwxvzpdex0Y8xlzi3nqSYDUOfOnS8YaPXyyy8THx+f\n7XFly5YFYNeuXfTr1y/TfTp16kRCQkK253n55Zc5ceJE2uNrrrmGw8E2DFKFPH8O1vJU1URGwj//\naRuIlyyBNWvgttvsmrQqb8JoHFreDRw4kFmzZqV7btasWQwcONCn4y+55JJsR7TmJGPS/+KLL6gY\nRIuUGmPSpnNQoctT9ZLXwVqnT5+vqrniCvjiC9tA++uvMHeunRA32OeyDwRBl/TdmFm5X79+fP75\n52kLpuzYsYNdu3bRoUOHtH7zMTExNGvWjE8//fSC43fs2EHTpk0BO0XCgAEDaNy4MTfccEPa1Adg\n+697pmV+/PHHAXj11VfZtWsXnTt3prMzOUhkZCT79+8HYOLEiTRt2pSmTZumTcu8Y8cOGjduzO23\n306TJk3o3r17utfxmD9/Pm3atKFly5ZcddVV7N27F7BjAYYPH06zZs1o3rx52jQOX331FTExMURH\nR9O1a1fAri8wYcKEtHM2bdqUHTt2sGPHDi6//HKGDBlC06ZN+eOPPzJ9fwArVqzgL3/5C9HR0cTF\nxXH06FGuvPLKdFNGt2/fnsTExOx/Ucp1Y8faKpn//Mf3Y5KTbVVNZKTtV3/4MLz+uj3Piy+Crnvv\nX8E1qscllStXJi4uji+//JLrrruOWbNmcdNNNyEilCxZkrlz51K+fHn2799P27Zt6dOnT5brt06a\nNInSpUuzceNG1q5dS0xMTNq2Z555hsqVK3P27Fm6du3K2rVrufvuu5k4cSJLliyhatWq6c61cuVK\n3n77bX788UeMMbRp04aOHTtSqVIltmzZwsyZM3nrrbe46aab+Oijj7j11lvTHd++fXt++OEHRISp\nU6fy/PPP8+KLL/LUU09RoUIF1q1bB9g575OTk7n99ttZunQpdevWTTePTla2bNnCu+++S9u2bbN8\nf40aNeLmm2/mww8/pHXr1hw5coRSpUrx17/+lXfeeYeXX36ZzZs3c+rUKaJ1hE3A69nTTlM8caKt\nnsmuZJ6YaBt+P/gA/vzTToI2bZr9GU5z4RS2oEv6bs2s7Kni8ST9adOmAbbq4qGHHmLp0qUUKVKE\nnTt3snfvXqpXr57peZYuXcrdd98NQPPmzWnevHnattmzZzNlyhRSU1PZvXs3GzZsSLc9o2XLlnHD\nDTekzXjZt29fvvvuO/r06UPdunVp0aIFkH5qZm9JSUncfPPN7N69m9OnT1PXKVItWrQoXXVWpUqV\nmD9/PldeeWXaPr5Mv1ynTp20hJ/V+xMRatSoQevWrQEo76xY0b9/f5566ileeOEFpk+fzrBhw3J8\nPeU+z2CtO+/MfLDW2bMwb55N9t9+a7t7Dh9uq3EaN3Yn5nCj11MfXXfddSxevJhVq1Zx4sQJWrVq\nBdgJzJKTk1m5ciVr1qzh4osvztM0xtu3b2fChAksXryYtWvXcu211+bpPB4lvGaSympq5tGjRzNq\n1CjWrVvH5MmT8z39MqSfgtl7+uXcvr/SpUvTrVs3Pv30U2bPns2gQYNyHZtyx+DBF66sdfiwraq5\n7DK7zuz27XYitKQkmDRJE35h0qTvo7Jly9K5c2duu+22dA24nmmFIyIiWLJkCb/99lu257nyyiv5\n4IMPAPj5559Zu3YtYKdlLlOmDBUqVGDv3r18+eWXaceUK1eOo0ePXnCuDh068Mknn3DixAmOHz/O\n3Llz6ZCLcfApKSnUdPq8vfvuu2nPd+vWjTfeeCPt8aFDh2jbti1Lly5l+/btQPrpl1etWgXAqlWr\n0rZnlNX7u/zyy9m9ezcrVqwA4OjRo2kXqBEjRnD33XfTunXrtAVbVODzDNb69FM7F85dd9lRs/fd\nZ7tezpljG2fvvx/011r4NOnnwsCBA0lMTEyX9AcNGkRCQgLNmjVjxowZOS4IEh8fz7Fjx2jcuDGP\nPfZY2jeG6OhoWrZsSaNGjbjlllvSTcs8cuRIevTokdaQ6xETE8OwYcOIi4ujTZs2jBgxgpYtW/r8\nfp544gn69+9Pq1at0rUXPPLIIxw6dIimTZsSHR3NkiVLqFatGlOmTKFv375ER0enTYl84403cvDg\nQZo0acLrr79Ow4YNM32trN5f8eLF+fDDDxk9ejTR0dF069Yt7RtAq1atKF++vM65H4Q8g7WuuQam\nToV+/WDVKli6FG680W5T7hDjLJgdKGJjY03GfusbN26ksX7/Czu7du2iU6dO/PLLLxTJomVP/zYC\n17RpsGePHVR18cVuRxP6RGSlMSY2p/30eqsC0owZM3j44YeZOHFilglfBba//tXtCFRmNOmrgDRk\nyBCGDBnidhhKhZygKUIFWjWUcp/+TSiVe0GR9EuWLMmBAwf0n1ylMcZw4MABSpYs6XYoSgWVoKje\nqVWrFklJSSQnJ7sdigogJUuWpFatWm6HoVRQCYqkHxERkTYSVCmlVN4FRfWOUkop/9Ckr5RSYUST\nvlJKhZGAG5ErIslA9hPYZK8qsN9P4fiTxpU7GlfuaFy5E4px1THGVMtpp4BL+vklIgm+DEUubBpX\n7mhcuaNx5U44x6XVO0opFUY06SulVBgJxaQ/xe0AsqBx5Y7GlTsaV+6EbVwhV6evlFIqa6FY0ldK\nKZUFTfpKKRVGQibpi0gPEdkkIltFZJzb8XiIyHQR2SciP7sdi4eIXCoiS0Rkg4isF5F73I4JQERK\nishPIpLoxPWk2zF5E5GiIrJaRD5zOxZvIrJDRNaJyBoRScj5iMIhIhVFZI6I/CIiG0XkigCI6XLn\nc/LcjojIvW7HBSAiY5y/+59FZKaIFMgUsiFRpy8iRYHNQDcgCVgBDDTGbHA1MEBErgSOATOMMU3d\njgdARGoANYwxq0SkHLASuN7tz0tEBChjjDkmIhHAMuAeY8wPbsblISJjgVigvDGml9vxeIjIDiDW\nGBNQg41E5F3gO2PMVBEpDpQ2xhx2Oy4PJ2/sBNoYY/IzINQfsdTE/r1HGWNOishs4AtjzDv+fq1Q\nKenHAVuNMduMMaeBWcB1LscEgDFmKXDQ7Ti8GWN2G2NWOfePAhuBmu5GBcY65jyMcG4BUSoRkVrA\ntcBUt2MJBiJSAbgSmAZgjDkdSAnf0RX41e2E76UYUEpEigGlgV0F8SKhkvRrAn94PU4iAJJYMBCR\nSKAl8KO7kVhOFcoaYB+w0BgTEHEBLwMPAOfcDiQTBviviKwUkZFuB+OoCyQDbztVYlNFpIzbQWUw\nAJjpdhAAxpidwATgd2A3kGKM+W9BvFaoJH2VByJSFvgIuNcYc8TteACMMWeNMS2AWkCciLheJSYi\nvYB9xpiVbseShfbGmBigJ3CXU6XotmJADDDJGNMSOA4EUltbcaAP8B+3YwEQkUrY2om6wCVAGRG5\ntSBeK1SS/k7gUq/HtZznVBacOvOPgPeNMR+7HU9GTlXAEqCH27EA7YA+Tt35LKCLiPzb3ZDOc0qJ\nGGP2AXOx1Z1uSwKSvL6pzcFeBAJFT2CVMWav24E4rgK2G2OSjTFngI+BvxTEC4VK0l8BNBCRus4V\nfAAwz+WYApbTYDoN2GiMmeh2PB4iUk1EKjr3S2Eb5n9xNyowxjxojKlljInE/m19bYwpkFJYbolI\nGacxHqf6pDvgek8xY8we4A8Rudx5qivgescKLwMJkKodx+9AWxEp7fx/dsW2tfldUCyXmBNjTKqI\njAIWAEWB6caY9S6HBYCIzAQ6AVVFJAl43Bgzzd2oaAcMBtY59ecADxljvnAxJoAawLtOr4oiwGxj\nTEB1jwxAFwNzbZ6gGPCBMeYrd0NKMxp43ymIbQOGuxwPkHZx7Abc4XYsHsaYH0VkDrAKSAVWU0BT\nMoREl02llFK+CZXqHaWUUj7QpK+UUmFEk75SSoURTfpKKRVGNOkrpVQY0aSvlFJhRJO+UkqFkf8H\nJ/4j7aZf91YAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}