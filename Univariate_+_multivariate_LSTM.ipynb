{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Univariate + multivariate LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luoChengwen/Tensorflow_test/blob/master/Univariate_%2B_multivariate_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoiXHNyX5Bw-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "49f2c6e1-4aa4-4912-bff1-e98c5c6f68ff"
      },
      "source": [
        "# ! pip install tensorflow==2.0.0-beta"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==2.0.0-beta in /usr/local/lib/python3.6/dist-packages (2.0.0b0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta) (1.11.2)\n",
            "Requirement already satisfied: tf-estimator-nightly<1.14.0.dev2019060502,>=1.14.0.dev2019060501 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta) (1.14.0.dev2019060501)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta) (1.12.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta) (0.8.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta) (0.2.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta) (1.17.3)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta) (3.10.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta) (0.33.6)\n",
            "Requirement already satisfied: tb-nightly<1.14.0a20190604,>=1.14.0a20190603 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta) (1.14.0a20190603)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta) (0.8.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta) (0.1.7)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta) (1.0.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==2.0.0-beta) (41.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta) (0.16.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==2.0.0-beta) (2.8.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbTO42-t42Is",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# univariate lstm example\n",
        "from numpy import array\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Dense\n",
        " \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GJydUWhVMcS",
        "colab_type": "text"
      },
      "source": [
        "## Univariate LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXnTL5lx48HB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split a univariate sequence into samples\n",
        "def split_sequence(sequence, n_steps):\n",
        "\tX, y = list(), list()\n",
        "\tfor i in range(len(sequence)):\n",
        "\t\t# find the end of this pattern\n",
        "\t\tend_ix = i + n_steps\n",
        "\t\t# check if we are beyond the sequence\n",
        "\t\tif end_ix > len(sequence)-1:\n",
        "\t\t\tbreak\n",
        "\t\t# gather input and output parts of the pattern\n",
        "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
        "\t\tX.append(seq_x)\n",
        "\t\ty.append(seq_y)\n",
        "\treturn array(X), array(y)\n",
        " \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8wiJo5E5BFd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define input sequence\n",
        "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
        "# choose a number of time steps\n",
        "n_steps = 3\n",
        "# split into samples\n",
        "X, y = split_sequence(raw_seq, n_steps)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPPMZ77NRVLd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "b611bb1f-365e-4756-caa9-f032b807f040"
      },
      "source": [
        "X, y"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[10, 20, 30],\n",
              "        [20, 30, 40],\n",
              "        [30, 40, 50],\n",
              "        [40, 50, 60],\n",
              "        [50, 60, 70],\n",
              "        [60, 70, 80]]), array([40, 50, 60, 70, 80, 90]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaYahyS_RcQ4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "754e06e2-e1f0-4631-c47b-2b61d9121916"
      },
      "source": [
        "(X.shape[0], X.shape[1], 1)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 3, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tkig80l-RVmQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f5227050-3b20-48ee-ed4e-3c75ee5d4571"
      },
      "source": [
        "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
        "n_features = 1\n",
        "X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, activation='relu', input_shape=(n_steps, n_features)))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "# fit model\n",
        "model.fit(X, y, epochs=200, verbose=0)\n",
        "# demonstrate prediction\n",
        "x_input = array([70, 80, 90])\n",
        "x_input = x_input.reshape((1, n_steps, n_features))\n",
        "yhat = model.predict(x_input, verbose=0)\n",
        "print(yhat)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[102.46112]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgecdERNVFm5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4714ece4-90d4-4eca-8bc7-d6401c15ca2c"
      },
      "source": [
        "n_steps, n_features"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EtMic6QW9xJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "de1d6de2-2c53-443c-b047-ccb8afc43e35"
      },
      "source": [
        "model2 = Sequential([\n",
        "                     LSTM(50,activation ='relu', return_sequences= True, input_shape = (X.shape[1],n_features)),\n",
        "                     LSTM(50,activation ='relu', return_sequences= True),\n",
        "                     LSTM(30,activation ='relu'),\n",
        "                     Dense(1)\n",
        "])\n",
        "model2.compile(optimizer='adam', loss='mse')\n",
        "model2.fit(X,y, epochs=200, verbose =0)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7faae6ce1128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBAIRXRjVIUj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c1e9c38b-71ec-4bd6-9ab0-cc8baf6c98b7"
      },
      "source": [
        "x_input = array([70, 80, 90])\n",
        "x_input = x_input.reshape((1, n_steps, n_features))\n",
        "model2.predict(x_input, verbose=0)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[101.84693]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FS40H-gQXyd_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b242278c-1649-4934-c126-aef0a280b2a8"
      },
      "source": [
        "from tensorflow.keras.layers import Bidirectional\n",
        "model3 = Sequential([\n",
        "                     Bidirectional(LSTM(32,activation ='relu', return_sequences=True), input_shape = (X.shape[1],n_features)),\n",
        "                     LSTM(16, activation='relu'),\n",
        "                     Dense(1)\n",
        "])\n",
        "model3.compile(optimizer='adam', loss='mse')\n",
        "model3.fit(X,y, epochs=200, verbose =0)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7faadb1b5a20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtQcBLX-Y319",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4af6bcca-f575-4ee8-df71-f9152d4e459e"
      },
      "source": [
        "x_input = array([70, 80, 90])\n",
        "x_input = x_input.reshape((1, n_steps, n_features))\n",
        "model3.predict(x_input, verbose=0)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[101.68855]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpACG0IcVQmM",
        "colab_type": "text"
      },
      "source": [
        "## Multivariate LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sIA5kuXm_rG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# define input sequence\n",
        "in_seq1 = array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
        "in_seq2 = array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
        "out_seq = array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnCseN1enA6v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMt2Dr3PnCy9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "71bd0cdc-3759-4d24-fb6e-5afbe220a8ac"
      },
      "source": [
        "plt.plot(in_seq1)\n",
        "plt.plot(in_seq2)\n",
        "plt.plot(out_seq)\n",
        "plt.legend(['seq1','seq2','outseq'])"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7faada200550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ntLkrpZQH0uaulFIeSJu7Ukp5oP8PRtZDr/MK2lcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYX7HgVTnExn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "863abf31-fb67-4229-b0bf-980f44783300"
      },
      "source": [
        "in_seq1"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([10, 20, 30, 40, 50, 60, 70, 80, 90])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7skQ80snzWm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "# convert to [rows, columns] structure\n",
        "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
        "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
        "out_seq = out_seq.reshape((len(out_seq), 1))\n",
        "# horizontally stack columns\n",
        "dataset = np.hstack((in_seq1, in_seq2, out_seq))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmW4lHqyn2h2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "8fbf794f-f427-4c92-8ae5-a40a60e138b5"
      },
      "source": [
        "in_seq1"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[10],\n",
              "       [20],\n",
              "       [30],\n",
              "       [40],\n",
              "       [50],\n",
              "       [60],\n",
              "       [70],\n",
              "       [80],\n",
              "       [90]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhelQ04Un7Y3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "0d1e9d26-23c6-4e3b-c9ce-8ea9a4e46dd5"
      },
      "source": [
        "dataset"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 10,  15,  25],\n",
              "       [ 20,  25,  45],\n",
              "       [ 30,  35,  65],\n",
              "       [ 40,  45,  85],\n",
              "       [ 50,  55, 105],\n",
              "       [ 60,  65, 125],\n",
              "       [ 70,  75, 145],\n",
              "       [ 80,  85, 165],\n",
              "       [ 90,  95, 185]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4HyC1sSn-7T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split a multivariate sequence into samples\n",
        "def split_sequences(sequences, n_steps):\n",
        "\tX, y = list(), list()\n",
        "\tfor i in range(len(sequences)):\n",
        "\t\t# find the end of this pattern\n",
        "\t\tend_ix = i + n_steps\n",
        "\t\t# check if we are beyond the dataset\n",
        "\t\tif end_ix > len(sequences):\n",
        "\t\t\tbreak\n",
        "\t\t# gather input and output parts of the pattern\n",
        "\t\tseq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]\n",
        "\t\tX.append(seq_x)\n",
        "\t\ty.append(seq_y)\n",
        "\treturn array(X), array(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkjhnaiooVUf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_steps = 3\n",
        "# convert into input/output\n",
        "X, y = split_sequences(dataset, n_steps)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRW8iV0codPi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "8cadceb3-2c1e-481b-cc98-5d4d0bfb836f"
      },
      "source": [
        "print(X.shape, y.shape)\n",
        "# summarize the data\n",
        "for i in range(len(X)):\n",
        "\tprint(X[i], y[i])"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7, 3, 2) (7,)\n",
            "[[10 15]\n",
            " [20 25]\n",
            " [30 35]] 65\n",
            "[[20 25]\n",
            " [30 35]\n",
            " [40 45]] 85\n",
            "[[30 35]\n",
            " [40 45]\n",
            " [50 55]] 105\n",
            "[[40 45]\n",
            " [50 55]\n",
            " [60 65]] 125\n",
            "[[50 55]\n",
            " [60 65]\n",
            " [70 75]] 145\n",
            "[[60 65]\n",
            " [70 75]\n",
            " [80 85]] 165\n",
            "[[70 75]\n",
            " [80 85]\n",
            " [90 95]] 185\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JyLEj3gowSi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "multi_model = Sequential([\n",
        "                          LSTM(50, activation='relu', input_shape=(3,2)),\n",
        "                          Dense(1)\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itEKrFPbpTSi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "multi_model.compile(optimizer='adam', loss='mse')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKxVSNySqTba",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "df79f44d-5cfb-478e-e84d-6a98deb02f27"
      },
      "source": [
        "multi_model.fit(X,y, epochs=200)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7 samples\n",
            "Epoch 1/200\n",
            "7/7 [==============================] - 0s 1ms/sample - loss: 17700.5098\n",
            "Epoch 2/200\n",
            "7/7 [==============================] - 0s 718us/sample - loss: 17243.9082\n",
            "Epoch 3/200\n",
            "7/7 [==============================] - 0s 610us/sample - loss: 16783.2617\n",
            "Epoch 4/200\n",
            "7/7 [==============================] - 0s 496us/sample - loss: 16324.7256\n",
            "Epoch 5/200\n",
            "7/7 [==============================] - 0s 472us/sample - loss: 15869.4014\n",
            "Epoch 6/200\n",
            "7/7 [==============================] - 0s 544us/sample - loss: 15417.2168\n",
            "Epoch 7/200\n",
            "7/7 [==============================] - 0s 529us/sample - loss: 14966.7627\n",
            "Epoch 8/200\n",
            "7/7 [==============================] - 0s 586us/sample - loss: 14516.0449\n",
            "Epoch 9/200\n",
            "7/7 [==============================] - 0s 830us/sample - loss: 14065.6455\n",
            "Epoch 10/200\n",
            "7/7 [==============================] - 0s 1ms/sample - loss: 13614.7871\n",
            "Epoch 11/200\n",
            "7/7 [==============================] - 0s 1ms/sample - loss: 13157.3389\n",
            "Epoch 12/200\n",
            "7/7 [==============================] - 0s 816us/sample - loss: 12692.2109\n",
            "Epoch 13/200\n",
            "7/7 [==============================] - 0s 667us/sample - loss: 12213.7725\n",
            "Epoch 14/200\n",
            "7/7 [==============================] - 0s 678us/sample - loss: 11718.5381\n",
            "Epoch 15/200\n",
            "7/7 [==============================] - 0s 725us/sample - loss: 11207.4229\n",
            "Epoch 16/200\n",
            "7/7 [==============================] - 0s 662us/sample - loss: 10682.7734\n",
            "Epoch 17/200\n",
            "7/7 [==============================] - 0s 643us/sample - loss: 10154.0840\n",
            "Epoch 18/200\n",
            "7/7 [==============================] - 0s 593us/sample - loss: 9633.3594\n",
            "Epoch 19/200\n",
            "7/7 [==============================] - 0s 794us/sample - loss: 9133.4268\n",
            "Epoch 20/200\n",
            "7/7 [==============================] - 0s 458us/sample - loss: 8653.6631\n",
            "Epoch 21/200\n",
            "7/7 [==============================] - 0s 499us/sample - loss: 8180.5249\n",
            "Epoch 22/200\n",
            "7/7 [==============================] - 0s 602us/sample - loss: 7688.5806\n",
            "Epoch 23/200\n",
            "7/7 [==============================] - 0s 453us/sample - loss: 7140.3467\n",
            "Epoch 24/200\n",
            "7/7 [==============================] - 0s 755us/sample - loss: 6498.6094\n",
            "Epoch 25/200\n",
            "7/7 [==============================] - 0s 635us/sample - loss: 5770.2681\n",
            "Epoch 26/200\n",
            "7/7 [==============================] - 0s 409us/sample - loss: 4980.1685\n",
            "Epoch 27/200\n",
            "7/7 [==============================] - 0s 518us/sample - loss: 4127.3013\n",
            "Epoch 28/200\n",
            "7/7 [==============================] - 0s 663us/sample - loss: 3261.6685\n",
            "Epoch 29/200\n",
            "7/7 [==============================] - 0s 1ms/sample - loss: 2488.9275\n",
            "Epoch 30/200\n",
            "7/7 [==============================] - 0s 1ms/sample - loss: 1863.0624\n",
            "Epoch 31/200\n",
            "7/7 [==============================] - 0s 901us/sample - loss: 1371.1150\n",
            "Epoch 32/200\n",
            "7/7 [==============================] - 0s 700us/sample - loss: 983.5984\n",
            "Epoch 33/200\n",
            "7/7 [==============================] - 0s 679us/sample - loss: 675.6259\n",
            "Epoch 34/200\n",
            "7/7 [==============================] - 0s 938us/sample - loss: 432.4474\n",
            "Epoch 35/200\n",
            "7/7 [==============================] - 0s 738us/sample - loss: 252.8776\n",
            "Epoch 36/200\n",
            "7/7 [==============================] - 0s 660us/sample - loss: 165.7380\n",
            "Epoch 37/200\n",
            "7/7 [==============================] - 0s 538us/sample - loss: 210.3014\n",
            "Epoch 38/200\n",
            "7/7 [==============================] - 0s 826us/sample - loss: 318.3619\n",
            "Epoch 39/200\n",
            "7/7 [==============================] - 0s 764us/sample - loss: 417.7749\n",
            "Epoch 40/200\n",
            "7/7 [==============================] - 0s 879us/sample - loss: 479.8436\n",
            "Epoch 41/200\n",
            "7/7 [==============================] - 0s 707us/sample - loss: 497.6248\n",
            "Epoch 42/200\n",
            "7/7 [==============================] - 0s 583us/sample - loss: 477.8835\n",
            "Epoch 43/200\n",
            "7/7 [==============================] - 0s 771us/sample - loss: 434.5060\n",
            "Epoch 44/200\n",
            "7/7 [==============================] - 0s 674us/sample - loss: 378.5719\n",
            "Epoch 45/200\n",
            "7/7 [==============================] - 0s 654us/sample - loss: 313.7158\n",
            "Epoch 46/200\n",
            "7/7 [==============================] - 0s 775us/sample - loss: 244.2699\n",
            "Epoch 47/200\n",
            "7/7 [==============================] - 0s 803us/sample - loss: 183.4252\n",
            "Epoch 48/200\n",
            "7/7 [==============================] - 0s 804us/sample - loss: 144.4546\n",
            "Epoch 49/200\n",
            "7/7 [==============================] - 0s 817us/sample - loss: 123.9183\n",
            "Epoch 50/200\n",
            "7/7 [==============================] - 0s 1ms/sample - loss: 113.5018\n",
            "Epoch 51/200\n",
            "7/7 [==============================] - 0s 591us/sample - loss: 108.6201\n",
            "Epoch 52/200\n",
            "7/7 [==============================] - 0s 825us/sample - loss: 107.0826\n",
            "Epoch 53/200\n",
            "7/7 [==============================] - 0s 853us/sample - loss: 107.5606\n",
            "Epoch 54/200\n",
            "7/7 [==============================] - 0s 883us/sample - loss: 109.1440\n",
            "Epoch 55/200\n",
            "7/7 [==============================] - 0s 876us/sample - loss: 111.0963\n",
            "Epoch 56/200\n",
            "7/7 [==============================] - 0s 786us/sample - loss: 112.8402\n",
            "Epoch 57/200\n",
            "7/7 [==============================] - 0s 772us/sample - loss: 113.8876\n",
            "Epoch 58/200\n",
            "7/7 [==============================] - 0s 803us/sample - loss: 113.9553\n",
            "Epoch 59/200\n",
            "7/7 [==============================] - 0s 746us/sample - loss: 112.9424\n",
            "Epoch 60/200\n",
            "7/7 [==============================] - 0s 861us/sample - loss: 110.8411\n",
            "Epoch 61/200\n",
            "7/7 [==============================] - 0s 759us/sample - loss: 107.7599\n",
            "Epoch 62/200\n",
            "7/7 [==============================] - 0s 800us/sample - loss: 103.9917\n",
            "Epoch 63/200\n",
            "7/7 [==============================] - 0s 766us/sample - loss: 99.8381\n",
            "Epoch 64/200\n",
            "7/7 [==============================] - 0s 731us/sample - loss: 95.5066\n",
            "Epoch 65/200\n",
            "7/7 [==============================] - 0s 718us/sample - loss: 91.1334\n",
            "Epoch 66/200\n",
            "7/7 [==============================] - 0s 730us/sample - loss: 86.8442\n",
            "Epoch 67/200\n",
            "7/7 [==============================] - 0s 749us/sample - loss: 82.7457\n",
            "Epoch 68/200\n",
            "7/7 [==============================] - 0s 802us/sample - loss: 78.8697\n",
            "Epoch 69/200\n",
            "7/7 [==============================] - 0s 780us/sample - loss: 75.1997\n",
            "Epoch 70/200\n",
            "7/7 [==============================] - 0s 785us/sample - loss: 71.7427\n",
            "Epoch 71/200\n",
            "7/7 [==============================] - 0s 722us/sample - loss: 68.5409\n",
            "Epoch 72/200\n",
            "7/7 [==============================] - 0s 809us/sample - loss: 65.6635\n",
            "Epoch 73/200\n",
            "7/7 [==============================] - 0s 822us/sample - loss: 63.1265\n",
            "Epoch 74/200\n",
            "7/7 [==============================] - 0s 728us/sample - loss: 60.7869\n",
            "Epoch 75/200\n",
            "7/7 [==============================] - 0s 1ms/sample - loss: 58.4750\n",
            "Epoch 76/200\n",
            "7/7 [==============================] - 0s 738us/sample - loss: 56.0686\n",
            "Epoch 77/200\n",
            "7/7 [==============================] - 0s 869us/sample - loss: 53.6160\n",
            "Epoch 78/200\n",
            "7/7 [==============================] - 0s 809us/sample - loss: 51.1203\n",
            "Epoch 79/200\n",
            "7/7 [==============================] - 0s 870us/sample - loss: 48.5774\n",
            "Epoch 80/200\n",
            "7/7 [==============================] - 0s 1ms/sample - loss: 45.9840\n",
            "Epoch 81/200\n",
            "7/7 [==============================] - 0s 1ms/sample - loss: 43.2806\n",
            "Epoch 82/200\n",
            "7/7 [==============================] - 0s 908us/sample - loss: 40.4461\n",
            "Epoch 83/200\n",
            "7/7 [==============================] - 0s 848us/sample - loss: 37.4596\n",
            "Epoch 84/200\n",
            "7/7 [==============================] - 0s 959us/sample - loss: 34.4259\n",
            "Epoch 85/200\n",
            "7/7 [==============================] - 0s 890us/sample - loss: 31.6259\n",
            "Epoch 86/200\n",
            "7/7 [==============================] - 0s 1ms/sample - loss: 28.7921\n",
            "Epoch 87/200\n",
            "7/7 [==============================] - 0s 1ms/sample - loss: 25.9501\n",
            "Epoch 88/200\n",
            "7/7 [==============================] - 0s 577us/sample - loss: 23.1472\n",
            "Epoch 89/200\n",
            "7/7 [==============================] - 0s 870us/sample - loss: 20.4203\n",
            "Epoch 90/200\n",
            "7/7 [==============================] - 0s 492us/sample - loss: 17.8191\n",
            "Epoch 91/200\n",
            "7/7 [==============================] - 0s 1ms/sample - loss: 15.4424\n",
            "Epoch 92/200\n",
            "7/7 [==============================] - 0s 1ms/sample - loss: 13.3865\n",
            "Epoch 93/200\n",
            "7/7 [==============================] - 0s 565us/sample - loss: 11.6975\n",
            "Epoch 94/200\n",
            "7/7 [==============================] - 0s 1ms/sample - loss: 10.3486\n",
            "Epoch 95/200\n",
            "7/7 [==============================] - 0s 1ms/sample - loss: 9.3869\n",
            "Epoch 96/200\n",
            "7/7 [==============================] - 0s 999us/sample - loss: 8.7690\n",
            "Epoch 97/200\n",
            "7/7 [==============================] - 0s 684us/sample - loss: 8.3904\n",
            "Epoch 98/200\n",
            "7/7 [==============================] - 0s 722us/sample - loss: 8.1558\n",
            "Epoch 99/200\n",
            "7/7 [==============================] - 0s 859us/sample - loss: 7.9777\n",
            "Epoch 100/200\n",
            "7/7 [==============================] - 0s 799us/sample - loss: 7.8099\n",
            "Epoch 101/200\n",
            "7/7 [==============================] - 0s 727us/sample - loss: 7.5893\n",
            "Epoch 102/200\n",
            "7/7 [==============================] - 0s 1ms/sample - loss: 7.2735\n",
            "Epoch 103/200\n",
            "7/7 [==============================] - 0s 1ms/sample - loss: 6.8721\n",
            "Epoch 104/200\n",
            "7/7 [==============================] - 0s 906us/sample - loss: 6.4505\n",
            "Epoch 105/200\n",
            "7/7 [==============================] - 0s 898us/sample - loss: 6.1261\n",
            "Epoch 106/200\n",
            "7/7 [==============================] - 0s 668us/sample - loss: 5.9104\n",
            "Epoch 107/200\n",
            "7/7 [==============================] - 0s 668us/sample - loss: 5.7265\n",
            "Epoch 108/200\n",
            "7/7 [==============================] - 0s 411us/sample - loss: 5.5177\n",
            "Epoch 109/200\n",
            "7/7 [==============================] - 0s 584us/sample - loss: 5.2696\n",
            "Epoch 110/200\n",
            "7/7 [==============================] - 0s 575us/sample - loss: 5.0099\n",
            "Epoch 111/200\n",
            "7/7 [==============================] - 0s 600us/sample - loss: 4.7776\n",
            "Epoch 112/200\n",
            "7/7 [==============================] - 0s 641us/sample - loss: 4.5908\n",
            "Epoch 113/200\n",
            "7/7 [==============================] - 0s 538us/sample - loss: 4.4371\n",
            "Epoch 114/200\n",
            "7/7 [==============================] - 0s 544us/sample - loss: 4.2906\n",
            "Epoch 115/200\n",
            "7/7 [==============================] - 0s 626us/sample - loss: 4.1309\n",
            "Epoch 116/200\n",
            "7/7 [==============================] - 0s 612us/sample - loss: 3.9607\n",
            "Epoch 117/200\n",
            "7/7 [==============================] - 0s 526us/sample - loss: 3.7981\n",
            "Epoch 118/200\n",
            "7/7 [==============================] - 0s 527us/sample - loss: 3.6584\n",
            "Epoch 119/200\n",
            "7/7 [==============================] - 0s 509us/sample - loss: 3.5428\n",
            "Epoch 120/200\n",
            "7/7 [==============================] - 0s 486us/sample - loss: 3.4409\n",
            "Epoch 121/200\n",
            "7/7 [==============================] - 0s 486us/sample - loss: 3.3403\n",
            "Epoch 122/200\n",
            "7/7 [==============================] - 0s 545us/sample - loss: 3.2353\n",
            "Epoch 123/200\n",
            "7/7 [==============================] - 0s 551us/sample - loss: 3.1284\n",
            "Epoch 124/200\n",
            "7/7 [==============================] - 0s 475us/sample - loss: 3.0265\n",
            "Epoch 125/200\n",
            "7/7 [==============================] - 0s 614us/sample - loss: 2.9344\n",
            "Epoch 126/200\n",
            "7/7 [==============================] - 0s 615us/sample - loss: 2.8519\n",
            "Epoch 127/200\n",
            "7/7 [==============================] - 0s 529us/sample - loss: 2.7746\n",
            "Epoch 128/200\n",
            "7/7 [==============================] - 0s 529us/sample - loss: 2.6984\n",
            "Epoch 129/200\n",
            "7/7 [==============================] - 0s 626us/sample - loss: 2.6193\n",
            "Epoch 130/200\n",
            "7/7 [==============================] - 0s 983us/sample - loss: 2.5387\n",
            "Epoch 131/200\n",
            "7/7 [==============================] - 0s 1ms/sample - loss: 2.4610\n",
            "Epoch 132/200\n",
            "7/7 [==============================] - 0s 1ms/sample - loss: 2.3893\n",
            "Epoch 133/200\n",
            "7/7 [==============================] - 0s 893us/sample - loss: 2.3244\n",
            "Epoch 134/200\n",
            "7/7 [==============================] - 0s 628us/sample - loss: 2.2638\n",
            "Epoch 135/200\n",
            "7/7 [==============================] - 0s 638us/sample - loss: 2.2050\n",
            "Epoch 136/200\n",
            "7/7 [==============================] - 0s 717us/sample - loss: 2.1468\n",
            "Epoch 137/200\n",
            "7/7 [==============================] - 0s 1ms/sample - loss: 2.0897\n",
            "Epoch 138/200\n",
            "7/7 [==============================] - 0s 985us/sample - loss: 2.0356\n",
            "Epoch 139/200\n",
            "7/7 [==============================] - 0s 823us/sample - loss: 1.9856\n",
            "Epoch 140/200\n",
            "7/7 [==============================] - 0s 651us/sample - loss: 1.9396\n",
            "Epoch 141/200\n",
            "7/7 [==============================] - 0s 1ms/sample - loss: 1.8963\n",
            "Epoch 142/200\n",
            "7/7 [==============================] - 0s 786us/sample - loss: 1.8543\n",
            "Epoch 143/200\n",
            "7/7 [==============================] - 0s 2ms/sample - loss: 1.8128\n",
            "Epoch 144/200\n",
            "7/7 [==============================] - 0s 1ms/sample - loss: 1.7719\n",
            "Epoch 145/200\n",
            "7/7 [==============================] - 0s 1ms/sample - loss: 1.7335\n",
            "Epoch 146/200\n",
            "7/7 [==============================] - 0s 991us/sample - loss: 1.6970\n",
            "Epoch 147/200\n",
            "7/7 [==============================] - 0s 611us/sample - loss: 1.6622\n",
            "Epoch 148/200\n",
            "7/7 [==============================] - 0s 527us/sample - loss: 1.6286\n",
            "Epoch 149/200\n",
            "7/7 [==============================] - 0s 479us/sample - loss: 1.5954\n",
            "Epoch 150/200\n",
            "7/7 [==============================] - 0s 485us/sample - loss: 1.5625\n",
            "Epoch 151/200\n",
            "7/7 [==============================] - 0s 505us/sample - loss: 1.5302\n",
            "Epoch 152/200\n",
            "7/7 [==============================] - 0s 1ms/sample - loss: 1.4989\n",
            "Epoch 153/200\n",
            "7/7 [==============================] - 0s 955us/sample - loss: 1.4689\n",
            "Epoch 154/200\n",
            "7/7 [==============================] - 0s 983us/sample - loss: 1.4400\n",
            "Epoch 155/200\n",
            "7/7 [==============================] - 0s 579us/sample - loss: 1.4124\n",
            "Epoch 156/200\n",
            "7/7 [==============================] - 0s 599us/sample - loss: 1.3854\n",
            "Epoch 157/200\n",
            "7/7 [==============================] - 0s 1ms/sample - loss: 1.3589\n",
            "Epoch 158/200\n",
            "7/7 [==============================] - 0s 589us/sample - loss: 1.3330\n",
            "Epoch 159/200\n",
            "7/7 [==============================] - 0s 995us/sample - loss: 1.3077\n",
            "Epoch 160/200\n",
            "7/7 [==============================] - 0s 669us/sample - loss: 1.2832\n",
            "Epoch 161/200\n",
            "7/7 [==============================] - 0s 980us/sample - loss: 1.2594\n",
            "Epoch 162/200\n",
            "7/7 [==============================] - 0s 875us/sample - loss: 1.2360\n",
            "Epoch 163/200\n",
            "7/7 [==============================] - 0s 1ms/sample - loss: 1.2130\n",
            "Epoch 164/200\n",
            "7/7 [==============================] - 0s 802us/sample - loss: 1.1906\n",
            "Epoch 165/200\n",
            "7/7 [==============================] - 0s 893us/sample - loss: 1.1686\n",
            "Epoch 166/200\n",
            "7/7 [==============================] - 0s 759us/sample - loss: 1.1469\n",
            "Epoch 167/200\n",
            "7/7 [==============================] - 0s 794us/sample - loss: 1.1255\n",
            "Epoch 168/200\n",
            "7/7 [==============================] - 0s 727us/sample - loss: 1.1043\n",
            "Epoch 169/200\n",
            "7/7 [==============================] - 0s 756us/sample - loss: 1.0834\n",
            "Epoch 170/200\n",
            "7/7 [==============================] - 0s 751us/sample - loss: 1.0629\n",
            "Epoch 171/200\n",
            "7/7 [==============================] - 0s 648us/sample - loss: 1.0427\n",
            "Epoch 172/200\n",
            "7/7 [==============================] - 0s 683us/sample - loss: 1.0227\n",
            "Epoch 173/200\n",
            "7/7 [==============================] - 0s 901us/sample - loss: 1.0030\n",
            "Epoch 174/200\n",
            "7/7 [==============================] - 0s 790us/sample - loss: 0.9836\n",
            "Epoch 175/200\n",
            "7/7 [==============================] - 0s 819us/sample - loss: 0.9644\n",
            "Epoch 176/200\n",
            "7/7 [==============================] - 0s 591us/sample - loss: 0.9455\n",
            "Epoch 177/200\n",
            "7/7 [==============================] - 0s 784us/sample - loss: 0.9270\n",
            "Epoch 178/200\n",
            "7/7 [==============================] - 0s 571us/sample - loss: 0.9087\n",
            "Epoch 179/200\n",
            "7/7 [==============================] - 0s 594us/sample - loss: 0.8904\n",
            "Epoch 180/200\n",
            "7/7 [==============================] - 0s 721us/sample - loss: 0.8724\n",
            "Epoch 181/200\n",
            "7/7 [==============================] - 0s 712us/sample - loss: 0.8544\n",
            "Epoch 182/200\n",
            "7/7 [==============================] - 0s 728us/sample - loss: 0.8366\n",
            "Epoch 183/200\n",
            "7/7 [==============================] - 0s 663us/sample - loss: 0.8189\n",
            "Epoch 184/200\n",
            "7/7 [==============================] - 0s 713us/sample - loss: 0.8013\n",
            "Epoch 185/200\n",
            "7/7 [==============================] - 0s 715us/sample - loss: 0.7841\n",
            "Epoch 186/200\n",
            "7/7 [==============================] - 0s 767us/sample - loss: 0.7671\n",
            "Epoch 187/200\n",
            "7/7 [==============================] - 0s 570us/sample - loss: 0.7503\n",
            "Epoch 188/200\n",
            "7/7 [==============================] - 0s 705us/sample - loss: 0.7338\n",
            "Epoch 189/200\n",
            "7/7 [==============================] - 0s 771us/sample - loss: 0.7174\n",
            "Epoch 190/200\n",
            "7/7 [==============================] - 0s 763us/sample - loss: 0.7012\n",
            "Epoch 191/200\n",
            "7/7 [==============================] - 0s 732us/sample - loss: 0.6855\n",
            "Epoch 192/200\n",
            "7/7 [==============================] - 0s 770us/sample - loss: 0.6701\n",
            "Epoch 193/200\n",
            "7/7 [==============================] - 0s 748us/sample - loss: 0.6549\n",
            "Epoch 194/200\n",
            "7/7 [==============================] - 0s 798us/sample - loss: 0.6398\n",
            "Epoch 195/200\n",
            "7/7 [==============================] - 0s 752us/sample - loss: 0.6249\n",
            "Epoch 196/200\n",
            "7/7 [==============================] - 0s 756us/sample - loss: 0.6101\n",
            "Epoch 197/200\n",
            "7/7 [==============================] - 0s 764us/sample - loss: 0.5956\n",
            "Epoch 198/200\n",
            "7/7 [==============================] - 0s 769us/sample - loss: 0.5811\n",
            "Epoch 199/200\n",
            "7/7 [==============================] - 0s 704us/sample - loss: 0.5669\n",
            "Epoch 200/200\n",
            "7/7 [==============================] - 0s 697us/sample - loss: 0.5530\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7faada192b38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54txsjZCpYu7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_input = array([[80, 85], [90, 95], [100, 105]])\n",
        "x_input = x_input.reshape((1, 3, 2))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZIPuxa0qpvD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f2ac3841-4fc1-49cc-cc8c-fcf66802fed8"
      },
      "source": [
        "x_input"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 80,  85],\n",
              "        [ 90,  95],\n",
              "        [100, 105]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRzCRL4Tqq1Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b4249edd-07e8-4c09-cb04-ef00c0bce3c4"
      },
      "source": [
        "multi_model.predict(x_input)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[207.3594]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zb8h2UqHqwVT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjU0GZw1rXG0",
        "colab_type": "text"
      },
      "source": [
        "# very nice post : \n",
        "https://machinelearningmastery.com/how-to-develop-lstm-models-for-time-series-forecasting/"
      ]
    }
  ]
}